{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":4548,"sourceType":"modelInstanceVersion","modelInstanceId":3340,"modelId":1016}],"dockerImageVersionId":30627,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Preparation","metadata":{}},{"cell_type":"code","source":"# Download and import the imagebind library\n# And then move the files around to their expected locations\n\n!pip install pytorchvideo ftfy einops\n!git clone https://github.com/facebookresearch/ImageBind.git\nimport sys \nsys.path.append(\"/kaggle/working/ImageBind/\") \nimport imagebind\nimport torch\nfrom imagebind import data\nfrom imagebind.models import imagebind_model\nfrom imagebind.models.imagebind_model import ModalityType\n\n!mkdir /kaggle/working/.checkpoints\n!ln -s /kaggle/input/imagebind/pytorch/huge/1/imagebind_huge.pth /kaggle/working/.checkpoints/imagebind_huge.pth\n\n!mkdir /kaggle/working/bpe\n!ln -s /kaggle/working/ImageBind/bpe/bpe_simple_vocab_16e6.txt.gz /kaggle/working/bpe/bpe_simple_vocab_16e6.txt.gz\n\n!mkdir /kaggle/working/.assets/.assets\n!ln -s /kaggle/working/ImageBind/.assets /kaggle/working/.assets","metadata":{"_kg_hide-output":true,"execution":{"iopub.status.busy":"2025-06-20T08:42:59.129580Z","iopub.execute_input":"2025-06-20T08:42:59.129803Z","iopub.status.idle":"2025-06-20T08:43:30.210468Z","shell.execute_reply.started":"2025-06-20T08:42:59.129781Z","shell.execute_reply":"2025-06-20T08:43:30.209237Z"},"trusted":true},"outputs":[{"name":"stdout","text":"Collecting pytorchvideo\n  Downloading pytorchvideo-0.1.5.tar.gz (132 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m132.7/132.7 kB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hCollecting ftfy\n  Obtaining dependency information for ftfy from https://files.pythonhosted.org/packages/ab/6e/81d47999aebc1b155f81eca4477a616a70f238a2549848c38983f3c22a82/ftfy-6.3.1-py3-none-any.whl.metadata\n  Downloading ftfy-6.3.1-py3-none-any.whl.metadata (7.3 kB)\nCollecting einops\n  Obtaining dependency information for einops from https://files.pythonhosted.org/packages/87/62/9773de14fe6c45c23649e98b83231fffd7b9892b6cf863251dc2afa73643/einops-0.8.1-py3-none-any.whl.metadata\n  Downloading einops-0.8.1-py3-none-any.whl.metadata (13 kB)\nCollecting fvcore (from pytorchvideo)\n  Downloading fvcore-0.1.5.post20221221.tar.gz (50 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.2/50.2 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hCollecting av (from pytorchvideo)\n  Obtaining dependency information for av from https://files.pythonhosted.org/packages/23/42/0eafe0de75de6a0db71add8e4ea51ebf090482bad3068f4a874c90fbd110/av-14.4.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\n  Downloading av-14.4.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.6 kB)\nCollecting parameterized (from pytorchvideo)\n  Obtaining dependency information for parameterized from https://files.pythonhosted.org/packages/00/2f/804f58f0b856ab3bf21617cccf5b39206e6c4c94c2cd227bde125ea6105f/parameterized-0.9.0-py2.py3-none-any.whl.metadata\n  Downloading parameterized-0.9.0-py2.py3-none-any.whl.metadata (18 kB)\nCollecting iopath (from pytorchvideo)\n  Downloading iopath-0.1.10.tar.gz (42 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.2/42.2 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from pytorchvideo) (3.1)\nRequirement already satisfied: wcwidth in /opt/conda/lib/python3.10/site-packages (from ftfy) (0.2.6)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from fvcore->pytorchvideo) (1.24.3)\nCollecting yacs>=0.1.6 (from fvcore->pytorchvideo)\n  Obtaining dependency information for yacs>=0.1.6 from https://files.pythonhosted.org/packages/38/4f/fe9a4d472aa867878ce3bb7efb16654c5d63672b86dc0e6e953a67018433/yacs-0.1.8-py3-none-any.whl.metadata\n  Downloading yacs-0.1.8-py3-none-any.whl.metadata (639 bytes)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from fvcore->pytorchvideo) (6.0.1)\nRequirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from fvcore->pytorchvideo) (4.66.1)\nRequirement already satisfied: termcolor>=1.1 in /opt/conda/lib/python3.10/site-packages (from fvcore->pytorchvideo) (2.3.0)\nRequirement already satisfied: Pillow in /opt/conda/lib/python3.10/site-packages (from fvcore->pytorchvideo) (10.1.0)\nRequirement already satisfied: tabulate in /opt/conda/lib/python3.10/site-packages (from fvcore->pytorchvideo) (0.9.0)\nRequirement already satisfied: typing_extensions in /opt/conda/lib/python3.10/site-packages (from iopath->pytorchvideo) (4.5.0)\nCollecting portalocker (from iopath->pytorchvideo)\n  Obtaining dependency information for portalocker from https://files.pythonhosted.org/packages/4b/a6/38c8e2f318bf67d338f4d629e93b0b4b9af331f455f0390ea8ce4a099b26/portalocker-3.2.0-py3-none-any.whl.metadata\n  Downloading portalocker-3.2.0-py3-none-any.whl.metadata (8.7 kB)\nDownloading ftfy-6.3.1-py3-none-any.whl (44 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.8/44.8 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading einops-0.8.1-py3-none-any.whl (64 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.4/64.4 kB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading av-14.4.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (34.8 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m34.8/34.8 MB\u001b[0m \u001b[31m39.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading parameterized-0.9.0-py2.py3-none-any.whl (20 kB)\nDownloading yacs-0.1.8-py3-none-any.whl (14 kB)\nDownloading portalocker-3.2.0-py3-none-any.whl (22 kB)\nBuilding wheels for collected packages: pytorchvideo, fvcore, iopath\n  Building wheel for pytorchvideo (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for pytorchvideo: filename=pytorchvideo-0.1.5-py3-none-any.whl size=188685 sha256=70d25e5f05fcd031b20782d3451732521cdb91300b6fbd6b8533c11c5da741a9\n  Stored in directory: /root/.cache/pip/wheels/ff/4e/81/0f72a543be9ed7eb737c95bfc5da4025e73226b44368074ece\n  Building wheel for fvcore (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for fvcore: filename=fvcore-0.1.5.post20221221-py3-none-any.whl size=61400 sha256=19c86acfaecf4b44dc5dafb8247d8f400f7bfb44520e362885d62eae45168291\n  Stored in directory: /root/.cache/pip/wheels/01/c0/af/77c1cf53a1be9e42a52b48e5af2169d40ec2e89f7362489dd0\n  Building wheel for iopath (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for iopath: filename=iopath-0.1.10-py3-none-any.whl size=31530 sha256=72a1da67a66a1807cf26e65b296f8d4d2cf070414f2011a5245d414d630e9f71\n  Stored in directory: /root/.cache/pip/wheels/9a/a3/b6/ac0fcd1b4ed5cfeb3db92e6a0e476cfd48ed0df92b91080c1d\nSuccessfully built pytorchvideo fvcore iopath\nInstalling collected packages: yacs, portalocker, parameterized, ftfy, einops, av, iopath, fvcore, pytorchvideo\nSuccessfully installed av-14.4.0 einops-0.8.1 ftfy-6.3.1 fvcore-0.1.5.post20221221 iopath-0.1.10 parameterized-0.9.0 portalocker-3.2.0 pytorchvideo-0.1.5 yacs-0.1.8\nCloning into 'ImageBind'...\nremote: Enumerating objects: 146, done.\u001b[K\nremote: Counting objects: 100% (88/88), done.\u001b[K\nremote: Compressing objects: 100% (49/49), done.\u001b[K\nremote: Total 146 (delta 60), reused 39 (delta 39), pack-reused 58 (from 1)\u001b[K\nReceiving objects: 100% (146/146), 2.64 MiB | 32.63 MiB/s, done.\nResolving deltas: 100% (68/68), done.\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torchvision/transforms/functional_tensor.py:5: UserWarning: The torchvision.transforms.functional_tensor module is deprecated in 0.15 and will be **removed in 0.17**. Please don't rely on it. You probably just need to use APIs in torchvision.transforms.functional or in torchvision.transforms.v2.functional.\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/torchvision/transforms/_functional_video.py:6: UserWarning: The 'torchvision.transforms._functional_video' module is deprecated since 0.12 and will be removed in the future. Please use the 'torchvision.transforms.functional' module instead.\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/torchvision/transforms/_transforms_video.py:22: UserWarning: The 'torchvision.transforms._transforms_video' module is deprecated since 0.12 and will be removed in the future. Please use the 'torchvision.transforms' module instead.\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"mkdir: cannot create directory '/kaggle/working/.assets/.assets': No such file or directory\n","output_type":"stream"}],"execution_count":1},{"cell_type":"markdown","source":"# Model testing","metadata":{}},{"cell_type":"code","source":"model = imagebind_model.imagebind_huge(pretrained=True)","metadata":{"execution":{"iopub.status.busy":"2025-06-20T08:43:51.729115Z","iopub.execute_input":"2025-06-20T08:43:51.730189Z","iopub.status.idle":"2025-06-20T08:44:34.710887Z","shell.execute_reply.started":"2025-06-20T08:43:51.730132Z","shell.execute_reply":"2025-06-20T08:44:34.710136Z"},"trusted":true},"outputs":[],"execution_count":2},{"cell_type":"code","source":"from imagebind import data\nimport torch\nfrom imagebind.models import imagebind_model\nfrom imagebind.models.imagebind_model import ModalityType\n\ntext_list=[\"A dog.\", \"A car\", \"A bird\"]\nimage_paths=[\".assets/dog_image.jpg\", \".assets/car_image.jpg\", \".assets/bird_image.jpg\"]\naudio_paths=[\".assets/dog_audio.wav\", \".assets/car_audio.wav\", \".assets/bird_audio.wav\"]\n\ndevice = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n\n# Instantiate model\nmodel = imagebind_model.imagebind_huge(pretrained=True)\nmodel.eval()\nmodel.to(device)\n\n# Load data\ninputs = {\n    ModalityType.TEXT: data.load_and_transform_text(text_list, device),\n    ModalityType.VISION: data.load_and_transform_vision_data(image_paths, device),\n    ModalityType.AUDIO: data.load_and_transform_audio_data(audio_paths, device),\n}\n\nwith torch.no_grad():\n    embeddings = model(inputs)\n\nprint(\n    \"Vision x Text: \",\n    torch.softmax(embeddings[ModalityType.VISION] @ embeddings[ModalityType.TEXT].T, dim=-1),\n)\nprint(\n    \"Audio x Text: \",\n    torch.softmax(embeddings[ModalityType.AUDIO] @ embeddings[ModalityType.TEXT].T, dim=-1),\n)\nprint(\n    \"Vision x Audio: \",\n    torch.softmax(embeddings[ModalityType.VISION] @ embeddings[ModalityType.AUDIO].T, dim=-1),\n)","metadata":{"execution":{"iopub.status.busy":"2025-06-20T08:44:38.907848Z","iopub.execute_input":"2025-06-20T08:44:38.908161Z","iopub.status.idle":"2025-06-20T08:45:03.462739Z","shell.execute_reply.started":"2025-06-20T08:44:38.908139Z","shell.execute_reply":"2025-06-20T08:45:03.461812Z"},"trusted":true},"outputs":[{"name":"stdout","text":"Vision x Text:  tensor([[9.9761e-01, 2.3694e-03, 1.8612e-05],\n        [3.3837e-05, 9.9994e-01, 2.4118e-05],\n        [4.7997e-05, 1.3496e-02, 9.8646e-01]], device='cuda:0')\nAudio x Text:  tensor([[1., 0., 0.],\n        [0., 1., 0.],\n        [0., 0., 1.]], device='cuda:0')\nVision x Audio:  tensor([[8.2412e-01, 8.6408e-02, 8.9467e-02],\n        [1.2290e-01, 7.3417e-01, 1.4294e-01],\n        [1.3700e-03, 7.3293e-04, 9.9790e-01]], device='cuda:0')\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"import os\nfrom functools import partial\nfrom types import SimpleNamespace\n\nimport torch\nimport torch.nn as nn\n\nfrom imagebind.models.helpers import (EinOpsRearrange, LearnableLogitScaling, Normalize,\n                            SelectElement, SelectEOSAndProject)\nfrom imagebind.models.multimodal_preprocessors import (AudioPreprocessor,\n                                             IMUPreprocessor, PadIm2Video,\n                                             PatchEmbedGeneric,\n                                             RGBDTPreprocessor,\n                                             SpatioTemporalPosEmbeddingHelper,\n                                             TextPreprocessor,\n                                             ThermalPreprocessor)\nfrom imagebind.models.transformer import MultiheadAttention, SimpleTransformer\n\nModalityType = SimpleNamespace(\n    VISION=\"vision\",\n    TEXT=\"text\",\n    AUDIO=\"audio\",\n    THERMAL=\"thermal\",\n    DEPTH=\"depth\",\n    IMU=\"imu\",\n)\n\n\nclass ImageBindModel(nn.Module):\n    def __init__(\n        self,\n        video_frames=2,\n        kernel_size=(2, 14, 14),\n        audio_kernel_size=16,\n        audio_stride=10,\n        out_embed_dim=768,\n        vision_embed_dim=1024,\n        vision_num_blocks=24,\n        vision_num_heads=16,\n        audio_embed_dim=768,\n        audio_num_blocks=12,\n        audio_num_heads=12,\n        audio_num_mel_bins=128,\n        audio_target_len=204,\n        audio_drop_path=0.1,\n        text_embed_dim=768,\n        text_num_blocks=12,\n        text_num_heads=12,\n        depth_embed_dim=384,\n        depth_kernel_size=16,\n        depth_num_blocks=12,\n        depth_num_heads=8,\n        depth_drop_path=0.0,\n        thermal_embed_dim=768,\n        thermal_kernel_size=16,\n        thermal_num_blocks=12,\n        thermal_num_heads=12,\n        thermal_drop_path=0.0,\n        imu_embed_dim=512,\n        imu_kernel_size=8,\n        imu_num_blocks=6,\n        imu_num_heads=8,\n        imu_drop_path=0.7,\n    ):\n        super().__init__()\n\n        self.modality_preprocessors = self._create_modality_preprocessors(\n            video_frames,\n            vision_embed_dim,\n            kernel_size,\n            text_embed_dim,\n            audio_embed_dim,\n            audio_kernel_size,\n            audio_stride,\n            audio_num_mel_bins,\n            audio_target_len,\n            depth_embed_dim,\n            depth_kernel_size,\n            thermal_embed_dim,\n            thermal_kernel_size,\n            imu_embed_dim,\n        )\n\n        self.modality_trunks = self._create_modality_trunks(\n            vision_embed_dim,\n            vision_num_blocks,\n            vision_num_heads,\n            text_embed_dim,\n            text_num_blocks,\n            text_num_heads,\n            audio_embed_dim,\n            audio_num_blocks,\n            audio_num_heads,\n            audio_drop_path,\n            depth_embed_dim,\n            depth_num_blocks,\n            depth_num_heads,\n            depth_drop_path,\n            thermal_embed_dim,\n            thermal_num_blocks,\n            thermal_num_heads,\n            thermal_drop_path,\n            imu_embed_dim,\n            imu_num_blocks,\n            imu_num_heads,\n            imu_drop_path,\n        )\n\n        self.modality_heads = self._create_modality_heads(\n            out_embed_dim,\n            vision_embed_dim,\n            text_embed_dim,\n            audio_embed_dim,\n            depth_embed_dim,\n            thermal_embed_dim,\n            imu_embed_dim,\n        )\n\n        self.modality_postprocessors = self._create_modality_postprocessors(\n            out_embed_dim\n        )\n\n    def _create_modality_preprocessors(\n        self,\n        video_frames=2,\n        vision_embed_dim=1024,\n        kernel_size=(2, 14, 14),\n        text_embed_dim=768,\n        audio_embed_dim=768,\n        audio_kernel_size=16,\n        audio_stride=10,\n        audio_num_mel_bins=128,\n        audio_target_len=204,\n        depth_embed_dim=768,\n        depth_kernel_size=16,\n        thermal_embed_dim=768,\n        thermal_kernel_size=16,\n        imu_embed_dim=512,\n    ):\n        rgbt_stem = PatchEmbedGeneric(\n            proj_stem=[\n                PadIm2Video(pad_type=\"repeat\", ntimes=2),\n                nn.Conv3d(\n                    in_channels=3,\n                    kernel_size=kernel_size,\n                    out_channels=vision_embed_dim,\n                    stride=kernel_size,\n                    bias=False,\n                ),\n            ]\n        )\n        rgbt_preprocessor = RGBDTPreprocessor(\n            img_size=[3, video_frames, 224, 224],\n            num_cls_tokens=1,\n            pos_embed_fn=partial(SpatioTemporalPosEmbeddingHelper, learnable=True),\n            rgbt_stem=rgbt_stem,\n            depth_stem=None,\n        )\n\n        text_preprocessor = TextPreprocessor(\n            context_length=77,\n            vocab_size=49408,\n            embed_dim=text_embed_dim,\n            causal_masking=True,\n        )\n\n        audio_stem = PatchEmbedGeneric(\n            proj_stem=[\n                nn.Conv2d(\n                    in_channels=1,\n                    kernel_size=audio_kernel_size,\n                    stride=audio_stride,\n                    out_channels=audio_embed_dim,\n                    bias=False,\n                ),\n            ],\n            norm_layer=nn.LayerNorm(normalized_shape=audio_embed_dim),\n        )\n        audio_preprocessor = AudioPreprocessor(\n            img_size=[1, audio_num_mel_bins, audio_target_len],\n            num_cls_tokens=1,\n            pos_embed_fn=partial(SpatioTemporalPosEmbeddingHelper, learnable=True),\n            audio_stem=audio_stem,\n        )\n\n        depth_stem = PatchEmbedGeneric(\n            [\n                nn.Conv2d(\n                    kernel_size=depth_kernel_size,\n                    in_channels=1,\n                    out_channels=depth_embed_dim,\n                    stride=depth_kernel_size,\n                    bias=False,\n                ),\n            ],\n            norm_layer=nn.LayerNorm(normalized_shape=depth_embed_dim),\n        )\n\n        depth_preprocessor = RGBDTPreprocessor(\n            img_size=[1, 224, 224],\n            num_cls_tokens=1,\n            pos_embed_fn=partial(SpatioTemporalPosEmbeddingHelper, learnable=True),\n            rgbt_stem=None,\n            depth_stem=depth_stem,\n        )\n\n        thermal_stem = PatchEmbedGeneric(\n            [\n                nn.Conv2d(\n                    kernel_size=thermal_kernel_size,\n                    in_channels=1,\n                    out_channels=thermal_embed_dim,\n                    stride=thermal_kernel_size,\n                    bias=False,\n                ),\n            ],\n            norm_layer=nn.LayerNorm(normalized_shape=thermal_embed_dim),\n        )\n        thermal_preprocessor = ThermalPreprocessor(\n            img_size=[1, 224, 224],\n            num_cls_tokens=1,\n            pos_embed_fn=partial(SpatioTemporalPosEmbeddingHelper, learnable=True),\n            thermal_stem=thermal_stem,\n        )\n\n        imu_stem = PatchEmbedGeneric(\n            [\n                nn.Linear(\n                    in_features=48,\n                    out_features=imu_embed_dim,\n                    bias=False,\n                ),\n            ],\n            norm_layer=nn.LayerNorm(normalized_shape=imu_embed_dim),\n        )\n\n        imu_preprocessor = IMUPreprocessor(\n            img_size=[6, 2000],\n            num_cls_tokens=1,\n            kernel_size=8,\n            embed_dim=imu_embed_dim,\n            pos_embed_fn=partial(SpatioTemporalPosEmbeddingHelper, learnable=True),\n            imu_stem=imu_stem,\n        )\n\n        modality_preprocessors = {\n            ModalityType.VISION: rgbt_preprocessor,\n            ModalityType.TEXT: text_preprocessor,\n            ModalityType.AUDIO: audio_preprocessor,\n            ModalityType.DEPTH: depth_preprocessor,\n            ModalityType.THERMAL: thermal_preprocessor,\n            ModalityType.IMU: imu_preprocessor,\n        }\n\n        return nn.ModuleDict(modality_preprocessors)\n\n    def _create_modality_trunks(\n        self,\n        vision_embed_dim=1024,\n        vision_num_blocks=24,\n        vision_num_heads=16,\n        text_embed_dim=768,\n        text_num_blocks=12,\n        text_num_heads=12,\n        audio_embed_dim=768,\n        audio_num_blocks=12,\n        audio_num_heads=12,\n        audio_drop_path=0.0,\n        depth_embed_dim=768,\n        depth_num_blocks=12,\n        depth_num_heads=12,\n        depth_drop_path=0.0,\n        thermal_embed_dim=768,\n        thermal_num_blocks=12,\n        thermal_num_heads=12,\n        thermal_drop_path=0.0,\n        imu_embed_dim=512,\n        imu_num_blocks=6,\n        imu_num_heads=8,\n        imu_drop_path=0.7,\n    ):\n        def instantiate_trunk(\n            embed_dim, num_blocks, num_heads, pre_transformer_ln, add_bias_kv, drop_path\n        ):\n            return SimpleTransformer(\n                embed_dim=embed_dim,\n                num_blocks=num_blocks,\n                ffn_dropout_rate=0.0,\n                drop_path_rate=drop_path,\n                attn_target=partial(\n                    MultiheadAttention,\n                    embed_dim=embed_dim,\n                    num_heads=num_heads,\n                    bias=True,\n                    add_bias_kv=add_bias_kv,\n                ),\n                pre_transformer_layer=nn.Sequential(\n                    nn.LayerNorm(embed_dim, eps=1e-6)\n                    if pre_transformer_ln\n                    else nn.Identity(),\n                    EinOpsRearrange(\"b l d -> l b d\"),\n                ),\n                post_transformer_layer=EinOpsRearrange(\"l b d -> b l d\"),\n            )\n\n        modality_trunks = {}\n        modality_trunks[ModalityType.VISION] = instantiate_trunk(\n            vision_embed_dim,\n            vision_num_blocks,\n            vision_num_heads,\n            pre_transformer_ln=True,\n            add_bias_kv=False,\n            drop_path=0.0,\n        )\n        modality_trunks[ModalityType.TEXT] = instantiate_trunk(\n            text_embed_dim,\n            text_num_blocks,\n            text_num_heads,\n            pre_transformer_ln=False,\n            add_bias_kv=False,\n            drop_path=0.0,\n        )\n        modality_trunks[ModalityType.AUDIO] = instantiate_trunk(\n            audio_embed_dim,\n            audio_num_blocks,\n            audio_num_heads,\n            pre_transformer_ln=False,\n            add_bias_kv=True,\n            drop_path=audio_drop_path,\n        )\n        modality_trunks[ModalityType.DEPTH] = instantiate_trunk(\n            depth_embed_dim,\n            depth_num_blocks,\n            depth_num_heads,\n            pre_transformer_ln=False,\n            add_bias_kv=True,\n            drop_path=depth_drop_path,\n        )\n        modality_trunks[ModalityType.THERMAL] = instantiate_trunk(\n            thermal_embed_dim,\n            thermal_num_blocks,\n            thermal_num_heads,\n            pre_transformer_ln=False,\n            add_bias_kv=True,\n            drop_path=thermal_drop_path,\n        )\n        modality_trunks[ModalityType.IMU] = instantiate_trunk(\n            imu_embed_dim,\n            imu_num_blocks,\n            imu_num_heads,\n            pre_transformer_ln=False,\n            add_bias_kv=True,\n            drop_path=imu_drop_path,\n        )\n\n        return nn.ModuleDict(modality_trunks)\n\n    def _create_modality_heads(\n        self,\n        out_embed_dim,\n        vision_embed_dim,\n        text_embed_dim,\n        audio_embed_dim,\n        depth_embed_dim,\n        thermal_embed_dim,\n        imu_embed_dim,\n    ):\n        modality_heads = {}\n\n        modality_heads[ModalityType.VISION] = nn.Sequential(\n            nn.LayerNorm(normalized_shape=vision_embed_dim, eps=1e-6),\n            SelectElement(index=0),\n            nn.Linear(vision_embed_dim, out_embed_dim, bias=False),\n        )\n\n        modality_heads[ModalityType.TEXT] = SelectEOSAndProject(\n            proj=nn.Sequential(\n                nn.LayerNorm(normalized_shape=text_embed_dim, eps=1e-6),\n                nn.Linear(text_embed_dim, out_embed_dim, bias=False),\n            )\n        )\n\n        modality_heads[ModalityType.AUDIO] = nn.Sequential(\n            nn.LayerNorm(normalized_shape=audio_embed_dim, eps=1e-6),\n            SelectElement(index=0),\n            nn.Linear(audio_embed_dim, out_embed_dim, bias=False),\n        )\n\n        modality_heads[ModalityType.DEPTH] = nn.Sequential(\n            nn.LayerNorm(normalized_shape=depth_embed_dim, eps=1e-6),\n            SelectElement(index=0),\n            nn.Linear(depth_embed_dim, out_embed_dim, bias=False),\n        )\n\n        modality_heads[ModalityType.THERMAL] = nn.Sequential(\n            nn.LayerNorm(normalized_shape=thermal_embed_dim, eps=1e-6),\n            SelectElement(index=0),\n            nn.Linear(thermal_embed_dim, out_embed_dim, bias=False),\n        )\n\n        modality_heads[ModalityType.IMU] = nn.Sequential(\n            nn.LayerNorm(normalized_shape=imu_embed_dim, eps=1e-6),\n            SelectElement(index=0),\n            nn.Dropout(p=0.5),\n            nn.Linear(imu_embed_dim, out_embed_dim, bias=False),\n        )\n\n        return nn.ModuleDict(modality_heads)\n\n    def _create_modality_postprocessors(self, out_embed_dim):\n        modality_postprocessors = {}\n\n        modality_postprocessors[ModalityType.VISION] = Normalize(dim=-1)\n        modality_postprocessors[ModalityType.TEXT] = nn.Sequential(\n            Normalize(dim=-1), LearnableLogitScaling(learnable=True)\n        )\n        modality_postprocessors[ModalityType.AUDIO] = nn.Sequential(\n            Normalize(dim=-1),\n            LearnableLogitScaling(logit_scale_init=20.0, learnable=False),\n        )\n        modality_postprocessors[ModalityType.DEPTH] = nn.Sequential(\n            Normalize(dim=-1),\n            LearnableLogitScaling(logit_scale_init=5.0, learnable=False),\n        )\n        modality_postprocessors[ModalityType.THERMAL] = nn.Sequential(\n            Normalize(dim=-1),\n            LearnableLogitScaling(logit_scale_init=10.0, learnable=False),\n        )\n        modality_postprocessors[ModalityType.IMU] = nn.Sequential(\n            Normalize(dim=-1),\n            LearnableLogitScaling(logit_scale_init=5.0, learnable=False),\n        )\n\n        return nn.ModuleDict(modality_postprocessors)\n\n    def forward(self, inputs):\n        outputs = {}\n        for modality_key, modality_value in inputs.items():\n            reduce_list = (\n                modality_value.ndim >= 5\n            )  # Audio and Video inputs consist of multiple clips\n            if reduce_list:\n                B, S = modality_value.shape[:2]\n                modality_value = modality_value.reshape(\n                    B * S, *modality_value.shape[2:]\n                )\n\n            if modality_value is not None:\n                modality_value = self.modality_preprocessors[modality_key](\n                    **{modality_key: modality_value}\n                )\n                trunk_inputs = modality_value[\"trunk\"]\n                head_inputs = modality_value[\"head\"]\n                modality_value = self.modality_trunks[modality_key](**trunk_inputs)\n                modality_value = self.modality_heads[modality_key](\n                    modality_value, **head_inputs\n                )\n                modality_value = self.modality_postprocessors[modality_key](\n                    modality_value\n                )\n\n                if reduce_list:\n                    modality_value = modality_value.reshape(B, S, -1)\n                    modality_value = modality_value.mean(dim=1)\n\n                outputs[modality_key] = modality_value\n\n        return outputs\n\n\ndef imagebind_huge(pretrained=False):\n    model = ImageBindModel(\n        vision_embed_dim=1280,\n        vision_num_blocks=32,\n        vision_num_heads=16,\n        text_embed_dim=1024,\n        text_num_blocks=24,\n        text_num_heads=16,\n        out_embed_dim=1024,\n        audio_drop_path=0.1,\n        imu_drop_path=0.7,\n    )\n\n    if pretrained:\n        if not os.path.exists(\".checkpoints/imagebind_huge.pth\"):\n            print(\n                \"Downloading imagebind weights to .checkpoints/imagebind_huge.pth ...\"\n            )\n            os.makedirs(\".checkpoints\", exist_ok=True)\n            torch.hub.download_url_to_file(\n                \"https://dl.fbaipublicfiles.com/imagebind/imagebind_huge.pth\",\n                \".checkpoints/imagebind_huge.pth\",\n                progress=True,\n            )\n\n        model.load_state_dict(torch.load(\".checkpoints/imagebind_huge.pth\"))\n\n    return model","metadata":{"execution":{"iopub.status.busy":"2025-06-20T08:45:32.235723Z","iopub.execute_input":"2025-06-20T08:45:32.236287Z","iopub.status.idle":"2025-06-20T08:45:32.270935Z","shell.execute_reply.started":"2025-06-20T08:45:32.236256Z","shell.execute_reply":"2025-06-20T08:45:32.270216Z"},"trusted":true},"outputs":[],"execution_count":4},{"cell_type":"code","source":"model","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-20T08:45:46.564123Z","iopub.execute_input":"2025-06-20T08:45:46.564795Z","iopub.status.idle":"2025-06-20T08:45:46.586661Z","shell.execute_reply.started":"2025-06-20T08:45:46.564764Z","shell.execute_reply":"2025-06-20T08:45:46.585666Z"}},"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"ImageBindModel(\n  (modality_preprocessors): ModuleDict(\n    (vision): RGBDTPreprocessor(\n      (cls_token): tensor((1, 1, 1280), requires_grad=True)\n      \n      (rgbt_stem): PatchEmbedGeneric(\n        (proj): Sequential(\n          (0): PadIm2Video()\n          (1): Conv3d(3, 1280, kernel_size=(2, 14, 14), stride=(2, 14, 14), bias=False)\n        )\n      )\n      (pos_embedding_helper): SpatioTemporalPosEmbeddingHelper(\n        (pos_embed): tensor((1, 257, 1280), requires_grad=True)\n        \n      )\n    )\n    (text): TextPreprocessor(\n      (pos_embed): tensor((1, 77, 1024), requires_grad=True)\n      (mask): tensor((77, 77), requires_grad=False)\n      \n      (token_embedding): Embedding(49408, 1024)\n    )\n    (audio): AudioPreprocessor(\n      (cls_token): tensor((1, 1, 768), requires_grad=True)\n      \n      (rgbt_stem): PatchEmbedGeneric(\n        (proj): Conv2d(1, 768, kernel_size=(16, 16), stride=(10, 10), bias=False)\n        (norm_layer): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n      )\n      (pos_embedding_helper): SpatioTemporalPosEmbeddingHelper(\n        (pos_embed): tensor((1, 229, 768), requires_grad=True)\n        \n      )\n    )\n    (depth): RGBDTPreprocessor(\n      (cls_token): tensor((1, 1, 384), requires_grad=True)\n      \n      (depth_stem): PatchEmbedGeneric(\n        (proj): Conv2d(1, 384, kernel_size=(16, 16), stride=(16, 16), bias=False)\n        (norm_layer): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n      )\n      (pos_embedding_helper): SpatioTemporalPosEmbeddingHelper(\n        (pos_embed): tensor((1, 197, 384), requires_grad=True)\n        \n      )\n    )\n    (thermal): ThermalPreprocessor(\n      (cls_token): tensor((1, 1, 768), requires_grad=True)\n      \n      (rgbt_stem): PatchEmbedGeneric(\n        (proj): Conv2d(1, 768, kernel_size=(16, 16), stride=(16, 16), bias=False)\n        (norm_layer): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n      )\n      (pos_embedding_helper): SpatioTemporalPosEmbeddingHelper(\n        (pos_embed): tensor((1, 197, 768), requires_grad=True)\n        \n      )\n    )\n    (imu): IMUPreprocessor(\n      (pos_embed): tensor((1, 251, 512), requires_grad=True)\n      (cls_token): tensor((1, 1, 512), requires_grad=True)\n      \n      (imu_stem): PatchEmbedGeneric(\n        (proj): Linear(in_features=48, out_features=512, bias=False)\n        (norm_layer): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n      )\n    )\n  )\n  (modality_trunks): ModuleDict(\n    (vision): SimpleTransformer(\n      (pre_transformer_layer): Sequential(\n        (0): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n        (1): EinOpsRearrange()\n      )\n      (blocks): Sequential(\n        (0): BlockWithMasking(\n          (attn): MultiheadAttention(\n            (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)\n          )\n          (drop_path): Identity()\n          (norm_1): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n          (mlp): Mlp(\n            (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n            (act): GELU(approximate='none')\n            (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n            (drop): Dropout(p=0.0, inplace=False)\n          )\n          (norm_2): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n        )\n        (1): BlockWithMasking(\n          (attn): MultiheadAttention(\n            (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)\n          )\n          (drop_path): Identity()\n          (norm_1): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n          (mlp): Mlp(\n            (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n            (act): GELU(approximate='none')\n            (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n            (drop): Dropout(p=0.0, inplace=False)\n          )\n          (norm_2): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n        )\n        (2): BlockWithMasking(\n          (attn): MultiheadAttention(\n            (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)\n          )\n          (drop_path): Identity()\n          (norm_1): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n          (mlp): Mlp(\n            (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n            (act): GELU(approximate='none')\n            (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n            (drop): Dropout(p=0.0, inplace=False)\n          )\n          (norm_2): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n        )\n        (3): BlockWithMasking(\n          (attn): MultiheadAttention(\n            (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)\n          )\n          (drop_path): Identity()\n          (norm_1): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n          (mlp): Mlp(\n            (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n            (act): GELU(approximate='none')\n            (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n            (drop): Dropout(p=0.0, inplace=False)\n          )\n          (norm_2): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n        )\n        (4): BlockWithMasking(\n          (attn): MultiheadAttention(\n            (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)\n          )\n          (drop_path): Identity()\n          (norm_1): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n          (mlp): Mlp(\n            (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n            (act): GELU(approximate='none')\n            (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n            (drop): Dropout(p=0.0, inplace=False)\n          )\n          (norm_2): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n        )\n        (5): BlockWithMasking(\n          (attn): MultiheadAttention(\n            (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)\n          )\n          (drop_path): Identity()\n          (norm_1): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n          (mlp): Mlp(\n            (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n            (act): GELU(approximate='none')\n            (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n            (drop): Dropout(p=0.0, inplace=False)\n          )\n          (norm_2): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n        )\n        (6): BlockWithMasking(\n          (attn): MultiheadAttention(\n            (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)\n          )\n          (drop_path): Identity()\n          (norm_1): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n          (mlp): Mlp(\n            (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n            (act): GELU(approximate='none')\n            (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n            (drop): Dropout(p=0.0, inplace=False)\n          )\n          (norm_2): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n        )\n        (7): BlockWithMasking(\n          (attn): MultiheadAttention(\n            (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)\n          )\n          (drop_path): Identity()\n          (norm_1): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n          (mlp): Mlp(\n            (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n            (act): GELU(approximate='none')\n            (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n            (drop): Dropout(p=0.0, inplace=False)\n          )\n          (norm_2): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n        )\n        (8): BlockWithMasking(\n          (attn): MultiheadAttention(\n            (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)\n          )\n          (drop_path): Identity()\n          (norm_1): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n          (mlp): Mlp(\n            (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n            (act): GELU(approximate='none')\n            (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n            (drop): Dropout(p=0.0, inplace=False)\n          )\n          (norm_2): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n        )\n        (9): BlockWithMasking(\n          (attn): MultiheadAttention(\n            (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)\n          )\n          (drop_path): Identity()\n          (norm_1): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n          (mlp): Mlp(\n            (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n            (act): GELU(approximate='none')\n            (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n            (drop): Dropout(p=0.0, inplace=False)\n          )\n          (norm_2): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n        )\n        (10): BlockWithMasking(\n          (attn): MultiheadAttention(\n            (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)\n          )\n          (drop_path): Identity()\n          (norm_1): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n          (mlp): Mlp(\n            (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n            (act): GELU(approximate='none')\n            (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n            (drop): Dropout(p=0.0, inplace=False)\n          )\n          (norm_2): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n        )\n        (11): BlockWithMasking(\n          (attn): MultiheadAttention(\n            (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)\n          )\n          (drop_path): Identity()\n          (norm_1): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n          (mlp): Mlp(\n            (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n            (act): GELU(approximate='none')\n            (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n            (drop): Dropout(p=0.0, inplace=False)\n          )\n          (norm_2): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n        )\n        (12): BlockWithMasking(\n          (attn): MultiheadAttention(\n            (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)\n          )\n          (drop_path): Identity()\n          (norm_1): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n          (mlp): Mlp(\n            (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n            (act): GELU(approximate='none')\n            (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n            (drop): Dropout(p=0.0, inplace=False)\n          )\n          (norm_2): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n        )\n        (13): BlockWithMasking(\n          (attn): MultiheadAttention(\n            (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)\n          )\n          (drop_path): Identity()\n          (norm_1): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n          (mlp): Mlp(\n            (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n            (act): GELU(approximate='none')\n            (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n            (drop): Dropout(p=0.0, inplace=False)\n          )\n          (norm_2): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n        )\n        (14): BlockWithMasking(\n          (attn): MultiheadAttention(\n            (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)\n          )\n          (drop_path): Identity()\n          (norm_1): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n          (mlp): Mlp(\n            (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n            (act): GELU(approximate='none')\n            (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n            (drop): Dropout(p=0.0, inplace=False)\n          )\n          (norm_2): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n        )\n        (15): BlockWithMasking(\n          (attn): MultiheadAttention(\n            (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)\n          )\n          (drop_path): Identity()\n          (norm_1): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n          (mlp): Mlp(\n            (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n            (act): GELU(approximate='none')\n            (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n            (drop): Dropout(p=0.0, inplace=False)\n          )\n          (norm_2): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n        )\n        (16): BlockWithMasking(\n          (attn): MultiheadAttention(\n            (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)\n          )\n          (drop_path): Identity()\n          (norm_1): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n          (mlp): Mlp(\n            (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n            (act): GELU(approximate='none')\n            (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n            (drop): Dropout(p=0.0, inplace=False)\n          )\n          (norm_2): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n        )\n        (17): BlockWithMasking(\n          (attn): MultiheadAttention(\n            (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)\n          )\n          (drop_path): Identity()\n          (norm_1): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n          (mlp): Mlp(\n            (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n            (act): GELU(approximate='none')\n            (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n            (drop): Dropout(p=0.0, inplace=False)\n          )\n          (norm_2): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n        )\n        (18): BlockWithMasking(\n          (attn): MultiheadAttention(\n            (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)\n          )\n          (drop_path): Identity()\n          (norm_1): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n          (mlp): Mlp(\n            (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n            (act): GELU(approximate='none')\n            (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n            (drop): Dropout(p=0.0, inplace=False)\n          )\n          (norm_2): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n        )\n        (19): BlockWithMasking(\n          (attn): MultiheadAttention(\n            (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)\n          )\n          (drop_path): Identity()\n          (norm_1): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n          (mlp): Mlp(\n            (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n            (act): GELU(approximate='none')\n            (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n            (drop): Dropout(p=0.0, inplace=False)\n          )\n          (norm_2): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n        )\n        (20): BlockWithMasking(\n          (attn): MultiheadAttention(\n            (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)\n          )\n          (drop_path): Identity()\n          (norm_1): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n          (mlp): Mlp(\n            (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n            (act): GELU(approximate='none')\n            (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n            (drop): Dropout(p=0.0, inplace=False)\n          )\n          (norm_2): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n        )\n        (21): BlockWithMasking(\n          (attn): MultiheadAttention(\n            (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)\n          )\n          (drop_path): Identity()\n          (norm_1): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n          (mlp): Mlp(\n            (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n            (act): GELU(approximate='none')\n            (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n            (drop): Dropout(p=0.0, inplace=False)\n          )\n          (norm_2): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n        )\n        (22): BlockWithMasking(\n          (attn): MultiheadAttention(\n            (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)\n          )\n          (drop_path): Identity()\n          (norm_1): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n          (mlp): Mlp(\n            (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n            (act): GELU(approximate='none')\n            (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n            (drop): Dropout(p=0.0, inplace=False)\n          )\n          (norm_2): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n        )\n        (23): BlockWithMasking(\n          (attn): MultiheadAttention(\n            (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)\n          )\n          (drop_path): Identity()\n          (norm_1): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n          (mlp): Mlp(\n            (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n            (act): GELU(approximate='none')\n            (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n            (drop): Dropout(p=0.0, inplace=False)\n          )\n          (norm_2): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n        )\n        (24): BlockWithMasking(\n          (attn): MultiheadAttention(\n            (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)\n          )\n          (drop_path): Identity()\n          (norm_1): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n          (mlp): Mlp(\n            (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n            (act): GELU(approximate='none')\n            (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n            (drop): Dropout(p=0.0, inplace=False)\n          )\n          (norm_2): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n        )\n        (25): BlockWithMasking(\n          (attn): MultiheadAttention(\n            (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)\n          )\n          (drop_path): Identity()\n          (norm_1): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n          (mlp): Mlp(\n            (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n            (act): GELU(approximate='none')\n            (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n            (drop): Dropout(p=0.0, inplace=False)\n          )\n          (norm_2): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n        )\n        (26): BlockWithMasking(\n          (attn): MultiheadAttention(\n            (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)\n          )\n          (drop_path): Identity()\n          (norm_1): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n          (mlp): Mlp(\n            (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n            (act): GELU(approximate='none')\n            (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n            (drop): Dropout(p=0.0, inplace=False)\n          )\n          (norm_2): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n        )\n        (27): BlockWithMasking(\n          (attn): MultiheadAttention(\n            (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)\n          )\n          (drop_path): Identity()\n          (norm_1): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n          (mlp): Mlp(\n            (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n            (act): GELU(approximate='none')\n            (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n            (drop): Dropout(p=0.0, inplace=False)\n          )\n          (norm_2): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n        )\n        (28): BlockWithMasking(\n          (attn): MultiheadAttention(\n            (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)\n          )\n          (drop_path): Identity()\n          (norm_1): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n          (mlp): Mlp(\n            (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n            (act): GELU(approximate='none')\n            (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n            (drop): Dropout(p=0.0, inplace=False)\n          )\n          (norm_2): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n        )\n        (29): BlockWithMasking(\n          (attn): MultiheadAttention(\n            (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)\n          )\n          (drop_path): Identity()\n          (norm_1): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n          (mlp): Mlp(\n            (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n            (act): GELU(approximate='none')\n            (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n            (drop): Dropout(p=0.0, inplace=False)\n          )\n          (norm_2): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n        )\n        (30): BlockWithMasking(\n          (attn): MultiheadAttention(\n            (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)\n          )\n          (drop_path): Identity()\n          (norm_1): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n          (mlp): Mlp(\n            (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n            (act): GELU(approximate='none')\n            (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n            (drop): Dropout(p=0.0, inplace=False)\n          )\n          (norm_2): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n        )\n        (31): BlockWithMasking(\n          (attn): MultiheadAttention(\n            (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)\n          )\n          (drop_path): Identity()\n          (norm_1): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n          (mlp): Mlp(\n            (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n            (act): GELU(approximate='none')\n            (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n            (drop): Dropout(p=0.0, inplace=False)\n          )\n          (norm_2): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n        )\n      )\n      (post_transformer_layer): EinOpsRearrange()\n    )\n    (text): SimpleTransformer(\n      (pre_transformer_layer): Sequential(\n        (0): Identity()\n        (1): EinOpsRearrange()\n      )\n      (blocks): Sequential(\n        (0): BlockWithMasking(\n          (attn): MultiheadAttention(\n            (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)\n          )\n          (drop_path): Identity()\n          (norm_1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n          (mlp): Mlp(\n            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n            (act): GELU(approximate='none')\n            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n            (drop): Dropout(p=0.0, inplace=False)\n          )\n          (norm_2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n        )\n        (1): BlockWithMasking(\n          (attn): MultiheadAttention(\n            (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)\n          )\n          (drop_path): Identity()\n          (norm_1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n          (mlp): Mlp(\n            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n            (act): GELU(approximate='none')\n            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n            (drop): Dropout(p=0.0, inplace=False)\n          )\n          (norm_2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n        )\n        (2): BlockWithMasking(\n          (attn): MultiheadAttention(\n            (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)\n          )\n          (drop_path): Identity()\n          (norm_1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n          (mlp): Mlp(\n            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n            (act): GELU(approximate='none')\n            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n            (drop): Dropout(p=0.0, inplace=False)\n          )\n          (norm_2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n        )\n        (3): BlockWithMasking(\n          (attn): MultiheadAttention(\n            (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)\n          )\n          (drop_path): Identity()\n          (norm_1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n          (mlp): Mlp(\n            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n            (act): GELU(approximate='none')\n            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n            (drop): Dropout(p=0.0, inplace=False)\n          )\n          (norm_2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n        )\n        (4): BlockWithMasking(\n          (attn): MultiheadAttention(\n            (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)\n          )\n          (drop_path): Identity()\n          (norm_1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n          (mlp): Mlp(\n            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n            (act): GELU(approximate='none')\n            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n            (drop): Dropout(p=0.0, inplace=False)\n          )\n          (norm_2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n        )\n        (5): BlockWithMasking(\n          (attn): MultiheadAttention(\n            (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)\n          )\n          (drop_path): Identity()\n          (norm_1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n          (mlp): Mlp(\n            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n            (act): GELU(approximate='none')\n            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n            (drop): Dropout(p=0.0, inplace=False)\n          )\n          (norm_2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n        )\n        (6): BlockWithMasking(\n          (attn): MultiheadAttention(\n            (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)\n          )\n          (drop_path): Identity()\n          (norm_1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n          (mlp): Mlp(\n            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n            (act): GELU(approximate='none')\n            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n            (drop): Dropout(p=0.0, inplace=False)\n          )\n          (norm_2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n        )\n        (7): BlockWithMasking(\n          (attn): MultiheadAttention(\n            (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)\n          )\n          (drop_path): Identity()\n          (norm_1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n          (mlp): Mlp(\n            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n            (act): GELU(approximate='none')\n            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n            (drop): Dropout(p=0.0, inplace=False)\n          )\n          (norm_2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n        )\n        (8): BlockWithMasking(\n          (attn): MultiheadAttention(\n            (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)\n          )\n          (drop_path): Identity()\n          (norm_1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n          (mlp): Mlp(\n            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n            (act): GELU(approximate='none')\n            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n            (drop): Dropout(p=0.0, inplace=False)\n          )\n          (norm_2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n        )\n        (9): BlockWithMasking(\n          (attn): MultiheadAttention(\n            (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)\n          )\n          (drop_path): Identity()\n          (norm_1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n          (mlp): Mlp(\n            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n            (act): GELU(approximate='none')\n            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n            (drop): Dropout(p=0.0, inplace=False)\n          )\n          (norm_2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n        )\n        (10): BlockWithMasking(\n          (attn): MultiheadAttention(\n            (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)\n          )\n          (drop_path): Identity()\n          (norm_1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n          (mlp): Mlp(\n            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n            (act): GELU(approximate='none')\n            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n            (drop): Dropout(p=0.0, inplace=False)\n          )\n          (norm_2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n        )\n        (11): BlockWithMasking(\n          (attn): MultiheadAttention(\n            (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)\n          )\n          (drop_path): Identity()\n          (norm_1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n          (mlp): Mlp(\n            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n            (act): GELU(approximate='none')\n            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n            (drop): Dropout(p=0.0, inplace=False)\n          )\n          (norm_2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n        )\n        (12): BlockWithMasking(\n          (attn): MultiheadAttention(\n            (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)\n          )\n          (drop_path): Identity()\n          (norm_1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n          (mlp): Mlp(\n            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n            (act): GELU(approximate='none')\n            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n            (drop): Dropout(p=0.0, inplace=False)\n          )\n          (norm_2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n        )\n        (13): BlockWithMasking(\n          (attn): MultiheadAttention(\n            (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)\n          )\n          (drop_path): Identity()\n          (norm_1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n          (mlp): Mlp(\n            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n            (act): GELU(approximate='none')\n            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n            (drop): Dropout(p=0.0, inplace=False)\n          )\n          (norm_2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n        )\n        (14): BlockWithMasking(\n          (attn): MultiheadAttention(\n            (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)\n          )\n          (drop_path): Identity()\n          (norm_1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n          (mlp): Mlp(\n            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n            (act): GELU(approximate='none')\n            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n            (drop): Dropout(p=0.0, inplace=False)\n          )\n          (norm_2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n        )\n        (15): BlockWithMasking(\n          (attn): MultiheadAttention(\n            (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)\n          )\n          (drop_path): Identity()\n          (norm_1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n          (mlp): Mlp(\n            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n            (act): GELU(approximate='none')\n            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n            (drop): Dropout(p=0.0, inplace=False)\n          )\n          (norm_2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n        )\n        (16): BlockWithMasking(\n          (attn): MultiheadAttention(\n            (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)\n          )\n          (drop_path): Identity()\n          (norm_1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n          (mlp): Mlp(\n            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n            (act): GELU(approximate='none')\n            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n            (drop): Dropout(p=0.0, inplace=False)\n          )\n          (norm_2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n        )\n        (17): BlockWithMasking(\n          (attn): MultiheadAttention(\n            (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)\n          )\n          (drop_path): Identity()\n          (norm_1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n          (mlp): Mlp(\n            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n            (act): GELU(approximate='none')\n            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n            (drop): Dropout(p=0.0, inplace=False)\n          )\n          (norm_2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n        )\n        (18): BlockWithMasking(\n          (attn): MultiheadAttention(\n            (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)\n          )\n          (drop_path): Identity()\n          (norm_1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n          (mlp): Mlp(\n            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n            (act): GELU(approximate='none')\n            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n            (drop): Dropout(p=0.0, inplace=False)\n          )\n          (norm_2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n        )\n        (19): BlockWithMasking(\n          (attn): MultiheadAttention(\n            (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)\n          )\n          (drop_path): Identity()\n          (norm_1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n          (mlp): Mlp(\n            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n            (act): GELU(approximate='none')\n            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n            (drop): Dropout(p=0.0, inplace=False)\n          )\n          (norm_2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n        )\n        (20): BlockWithMasking(\n          (attn): MultiheadAttention(\n            (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)\n          )\n          (drop_path): Identity()\n          (norm_1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n          (mlp): Mlp(\n            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n            (act): GELU(approximate='none')\n            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n            (drop): Dropout(p=0.0, inplace=False)\n          )\n          (norm_2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n        )\n        (21): BlockWithMasking(\n          (attn): MultiheadAttention(\n            (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)\n          )\n          (drop_path): Identity()\n          (norm_1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n          (mlp): Mlp(\n            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n            (act): GELU(approximate='none')\n            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n            (drop): Dropout(p=0.0, inplace=False)\n          )\n          (norm_2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n        )\n        (22): BlockWithMasking(\n          (attn): MultiheadAttention(\n            (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)\n          )\n          (drop_path): Identity()\n          (norm_1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n          (mlp): Mlp(\n            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n            (act): GELU(approximate='none')\n            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n            (drop): Dropout(p=0.0, inplace=False)\n          )\n          (norm_2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n        )\n        (23): BlockWithMasking(\n          (attn): MultiheadAttention(\n            (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)\n          )\n          (drop_path): Identity()\n          (norm_1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n          (mlp): Mlp(\n            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n            (act): GELU(approximate='none')\n            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n            (drop): Dropout(p=0.0, inplace=False)\n          )\n          (norm_2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n        )\n      )\n      (post_transformer_layer): EinOpsRearrange()\n    )\n    (audio): SimpleTransformer(\n      (pre_transformer_layer): Sequential(\n        (0): Identity()\n        (1): EinOpsRearrange()\n      )\n      (blocks): Sequential(\n        (0): BlockWithMasking(\n          (attn): MultiheadAttention(\n            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n          )\n          (drop_path): Identity()\n          (norm_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n          (mlp): Mlp(\n            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n            (act): GELU(approximate='none')\n            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n            (drop): Dropout(p=0.0, inplace=False)\n          )\n          (norm_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n        )\n        (1): BlockWithMasking(\n          (attn): MultiheadAttention(\n            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n          )\n          (drop_path): DropPath(drop_prob=0.009)\n          (norm_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n          (mlp): Mlp(\n            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n            (act): GELU(approximate='none')\n            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n            (drop): Dropout(p=0.0, inplace=False)\n          )\n          (norm_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n        )\n        (2): BlockWithMasking(\n          (attn): MultiheadAttention(\n            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n          )\n          (drop_path): DropPath(drop_prob=0.018)\n          (norm_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n          (mlp): Mlp(\n            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n            (act): GELU(approximate='none')\n            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n            (drop): Dropout(p=0.0, inplace=False)\n          )\n          (norm_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n        )\n        (3): BlockWithMasking(\n          (attn): MultiheadAttention(\n            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n          )\n          (drop_path): DropPath(drop_prob=0.027)\n          (norm_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n          (mlp): Mlp(\n            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n            (act): GELU(approximate='none')\n            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n            (drop): Dropout(p=0.0, inplace=False)\n          )\n          (norm_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n        )\n        (4): BlockWithMasking(\n          (attn): MultiheadAttention(\n            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n          )\n          (drop_path): DropPath(drop_prob=0.036)\n          (norm_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n          (mlp): Mlp(\n            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n            (act): GELU(approximate='none')\n            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n            (drop): Dropout(p=0.0, inplace=False)\n          )\n          (norm_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n        )\n        (5): BlockWithMasking(\n          (attn): MultiheadAttention(\n            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n          )\n          (drop_path): DropPath(drop_prob=0.045)\n          (norm_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n          (mlp): Mlp(\n            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n            (act): GELU(approximate='none')\n            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n            (drop): Dropout(p=0.0, inplace=False)\n          )\n          (norm_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n        )\n        (6): BlockWithMasking(\n          (attn): MultiheadAttention(\n            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n          )\n          (drop_path): DropPath(drop_prob=0.055)\n          (norm_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n          (mlp): Mlp(\n            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n            (act): GELU(approximate='none')\n            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n            (drop): Dropout(p=0.0, inplace=False)\n          )\n          (norm_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n        )\n        (7): BlockWithMasking(\n          (attn): MultiheadAttention(\n            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n          )\n          (drop_path): DropPath(drop_prob=0.064)\n          (norm_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n          (mlp): Mlp(\n            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n            (act): GELU(approximate='none')\n            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n            (drop): Dropout(p=0.0, inplace=False)\n          )\n          (norm_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n        )\n        (8): BlockWithMasking(\n          (attn): MultiheadAttention(\n            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n          )\n          (drop_path): DropPath(drop_prob=0.073)\n          (norm_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n          (mlp): Mlp(\n            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n            (act): GELU(approximate='none')\n            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n            (drop): Dropout(p=0.0, inplace=False)\n          )\n          (norm_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n        )\n        (9): BlockWithMasking(\n          (attn): MultiheadAttention(\n            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n          )\n          (drop_path): DropPath(drop_prob=0.082)\n          (norm_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n          (mlp): Mlp(\n            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n            (act): GELU(approximate='none')\n            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n            (drop): Dropout(p=0.0, inplace=False)\n          )\n          (norm_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n        )\n        (10): BlockWithMasking(\n          (attn): MultiheadAttention(\n            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n          )\n          (drop_path): DropPath(drop_prob=0.091)\n          (norm_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n          (mlp): Mlp(\n            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n            (act): GELU(approximate='none')\n            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n            (drop): Dropout(p=0.0, inplace=False)\n          )\n          (norm_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n        )\n        (11): BlockWithMasking(\n          (attn): MultiheadAttention(\n            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n          )\n          (drop_path): DropPath(drop_prob=0.100)\n          (norm_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n          (mlp): Mlp(\n            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n            (act): GELU(approximate='none')\n            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n            (drop): Dropout(p=0.0, inplace=False)\n          )\n          (norm_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n        )\n      )\n      (post_transformer_layer): EinOpsRearrange()\n    )\n    (depth): SimpleTransformer(\n      (pre_transformer_layer): Sequential(\n        (0): Identity()\n        (1): EinOpsRearrange()\n      )\n      (blocks): Sequential(\n        (0): BlockWithMasking(\n          (attn): MultiheadAttention(\n            (out_proj): NonDynamicallyQuantizableLinear(in_features=384, out_features=384, bias=True)\n          )\n          (drop_path): Identity()\n          (norm_1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n          (mlp): Mlp(\n            (fc1): Linear(in_features=384, out_features=1536, bias=True)\n            (act): GELU(approximate='none')\n            (fc2): Linear(in_features=1536, out_features=384, bias=True)\n            (drop): Dropout(p=0.0, inplace=False)\n          )\n          (norm_2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n        )\n        (1): BlockWithMasking(\n          (attn): MultiheadAttention(\n            (out_proj): NonDynamicallyQuantizableLinear(in_features=384, out_features=384, bias=True)\n          )\n          (drop_path): Identity()\n          (norm_1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n          (mlp): Mlp(\n            (fc1): Linear(in_features=384, out_features=1536, bias=True)\n            (act): GELU(approximate='none')\n            (fc2): Linear(in_features=1536, out_features=384, bias=True)\n            (drop): Dropout(p=0.0, inplace=False)\n          )\n          (norm_2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n        )\n        (2): BlockWithMasking(\n          (attn): MultiheadAttention(\n            (out_proj): NonDynamicallyQuantizableLinear(in_features=384, out_features=384, bias=True)\n          )\n          (drop_path): Identity()\n          (norm_1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n          (mlp): Mlp(\n            (fc1): Linear(in_features=384, out_features=1536, bias=True)\n            (act): GELU(approximate='none')\n            (fc2): Linear(in_features=1536, out_features=384, bias=True)\n            (drop): Dropout(p=0.0, inplace=False)\n          )\n          (norm_2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n        )\n        (3): BlockWithMasking(\n          (attn): MultiheadAttention(\n            (out_proj): NonDynamicallyQuantizableLinear(in_features=384, out_features=384, bias=True)\n          )\n          (drop_path): Identity()\n          (norm_1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n          (mlp): Mlp(\n            (fc1): Linear(in_features=384, out_features=1536, bias=True)\n            (act): GELU(approximate='none')\n            (fc2): Linear(in_features=1536, out_features=384, bias=True)\n            (drop): Dropout(p=0.0, inplace=False)\n          )\n          (norm_2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n        )\n        (4): BlockWithMasking(\n          (attn): MultiheadAttention(\n            (out_proj): NonDynamicallyQuantizableLinear(in_features=384, out_features=384, bias=True)\n          )\n          (drop_path): Identity()\n          (norm_1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n          (mlp): Mlp(\n            (fc1): Linear(in_features=384, out_features=1536, bias=True)\n            (act): GELU(approximate='none')\n            (fc2): Linear(in_features=1536, out_features=384, bias=True)\n            (drop): Dropout(p=0.0, inplace=False)\n          )\n          (norm_2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n        )\n        (5): BlockWithMasking(\n          (attn): MultiheadAttention(\n            (out_proj): NonDynamicallyQuantizableLinear(in_features=384, out_features=384, bias=True)\n          )\n          (drop_path): Identity()\n          (norm_1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n          (mlp): Mlp(\n            (fc1): Linear(in_features=384, out_features=1536, bias=True)\n            (act): GELU(approximate='none')\n            (fc2): Linear(in_features=1536, out_features=384, bias=True)\n            (drop): Dropout(p=0.0, inplace=False)\n          )\n          (norm_2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n        )\n        (6): BlockWithMasking(\n          (attn): MultiheadAttention(\n            (out_proj): NonDynamicallyQuantizableLinear(in_features=384, out_features=384, bias=True)\n          )\n          (drop_path): Identity()\n          (norm_1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n          (mlp): Mlp(\n            (fc1): Linear(in_features=384, out_features=1536, bias=True)\n            (act): GELU(approximate='none')\n            (fc2): Linear(in_features=1536, out_features=384, bias=True)\n            (drop): Dropout(p=0.0, inplace=False)\n          )\n          (norm_2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n        )\n        (7): BlockWithMasking(\n          (attn): MultiheadAttention(\n            (out_proj): NonDynamicallyQuantizableLinear(in_features=384, out_features=384, bias=True)\n          )\n          (drop_path): Identity()\n          (norm_1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n          (mlp): Mlp(\n            (fc1): Linear(in_features=384, out_features=1536, bias=True)\n            (act): GELU(approximate='none')\n            (fc2): Linear(in_features=1536, out_features=384, bias=True)\n            (drop): Dropout(p=0.0, inplace=False)\n          )\n          (norm_2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n        )\n        (8): BlockWithMasking(\n          (attn): MultiheadAttention(\n            (out_proj): NonDynamicallyQuantizableLinear(in_features=384, out_features=384, bias=True)\n          )\n          (drop_path): Identity()\n          (norm_1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n          (mlp): Mlp(\n            (fc1): Linear(in_features=384, out_features=1536, bias=True)\n            (act): GELU(approximate='none')\n            (fc2): Linear(in_features=1536, out_features=384, bias=True)\n            (drop): Dropout(p=0.0, inplace=False)\n          )\n          (norm_2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n        )\n        (9): BlockWithMasking(\n          (attn): MultiheadAttention(\n            (out_proj): NonDynamicallyQuantizableLinear(in_features=384, out_features=384, bias=True)\n          )\n          (drop_path): Identity()\n          (norm_1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n          (mlp): Mlp(\n            (fc1): Linear(in_features=384, out_features=1536, bias=True)\n            (act): GELU(approximate='none')\n            (fc2): Linear(in_features=1536, out_features=384, bias=True)\n            (drop): Dropout(p=0.0, inplace=False)\n          )\n          (norm_2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n        )\n        (10): BlockWithMasking(\n          (attn): MultiheadAttention(\n            (out_proj): NonDynamicallyQuantizableLinear(in_features=384, out_features=384, bias=True)\n          )\n          (drop_path): Identity()\n          (norm_1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n          (mlp): Mlp(\n            (fc1): Linear(in_features=384, out_features=1536, bias=True)\n            (act): GELU(approximate='none')\n            (fc2): Linear(in_features=1536, out_features=384, bias=True)\n            (drop): Dropout(p=0.0, inplace=False)\n          )\n          (norm_2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n        )\n        (11): BlockWithMasking(\n          (attn): MultiheadAttention(\n            (out_proj): NonDynamicallyQuantizableLinear(in_features=384, out_features=384, bias=True)\n          )\n          (drop_path): Identity()\n          (norm_1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n          (mlp): Mlp(\n            (fc1): Linear(in_features=384, out_features=1536, bias=True)\n            (act): GELU(approximate='none')\n            (fc2): Linear(in_features=1536, out_features=384, bias=True)\n            (drop): Dropout(p=0.0, inplace=False)\n          )\n          (norm_2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n        )\n      )\n      (post_transformer_layer): EinOpsRearrange()\n    )\n    (thermal): SimpleTransformer(\n      (pre_transformer_layer): Sequential(\n        (0): Identity()\n        (1): EinOpsRearrange()\n      )\n      (blocks): Sequential(\n        (0): BlockWithMasking(\n          (attn): MultiheadAttention(\n            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n          )\n          (drop_path): Identity()\n          (norm_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n          (mlp): Mlp(\n            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n            (act): GELU(approximate='none')\n            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n            (drop): Dropout(p=0.0, inplace=False)\n          )\n          (norm_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n        )\n        (1): BlockWithMasking(\n          (attn): MultiheadAttention(\n            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n          )\n          (drop_path): Identity()\n          (norm_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n          (mlp): Mlp(\n            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n            (act): GELU(approximate='none')\n            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n            (drop): Dropout(p=0.0, inplace=False)\n          )\n          (norm_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n        )\n        (2): BlockWithMasking(\n          (attn): MultiheadAttention(\n            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n          )\n          (drop_path): Identity()\n          (norm_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n          (mlp): Mlp(\n            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n            (act): GELU(approximate='none')\n            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n            (drop): Dropout(p=0.0, inplace=False)\n          )\n          (norm_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n        )\n        (3): BlockWithMasking(\n          (attn): MultiheadAttention(\n            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n          )\n          (drop_path): Identity()\n          (norm_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n          (mlp): Mlp(\n            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n            (act): GELU(approximate='none')\n            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n            (drop): Dropout(p=0.0, inplace=False)\n          )\n          (norm_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n        )\n        (4): BlockWithMasking(\n          (attn): MultiheadAttention(\n            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n          )\n          (drop_path): Identity()\n          (norm_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n          (mlp): Mlp(\n            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n            (act): GELU(approximate='none')\n            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n            (drop): Dropout(p=0.0, inplace=False)\n          )\n          (norm_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n        )\n        (5): BlockWithMasking(\n          (attn): MultiheadAttention(\n            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n          )\n          (drop_path): Identity()\n          (norm_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n          (mlp): Mlp(\n            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n            (act): GELU(approximate='none')\n            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n            (drop): Dropout(p=0.0, inplace=False)\n          )\n          (norm_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n        )\n        (6): BlockWithMasking(\n          (attn): MultiheadAttention(\n            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n          )\n          (drop_path): Identity()\n          (norm_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n          (mlp): Mlp(\n            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n            (act): GELU(approximate='none')\n            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n            (drop): Dropout(p=0.0, inplace=False)\n          )\n          (norm_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n        )\n        (7): BlockWithMasking(\n          (attn): MultiheadAttention(\n            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n          )\n          (drop_path): Identity()\n          (norm_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n          (mlp): Mlp(\n            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n            (act): GELU(approximate='none')\n            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n            (drop): Dropout(p=0.0, inplace=False)\n          )\n          (norm_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n        )\n        (8): BlockWithMasking(\n          (attn): MultiheadAttention(\n            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n          )\n          (drop_path): Identity()\n          (norm_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n          (mlp): Mlp(\n            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n            (act): GELU(approximate='none')\n            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n            (drop): Dropout(p=0.0, inplace=False)\n          )\n          (norm_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n        )\n        (9): BlockWithMasking(\n          (attn): MultiheadAttention(\n            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n          )\n          (drop_path): Identity()\n          (norm_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n          (mlp): Mlp(\n            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n            (act): GELU(approximate='none')\n            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n            (drop): Dropout(p=0.0, inplace=False)\n          )\n          (norm_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n        )\n        (10): BlockWithMasking(\n          (attn): MultiheadAttention(\n            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n          )\n          (drop_path): Identity()\n          (norm_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n          (mlp): Mlp(\n            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n            (act): GELU(approximate='none')\n            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n            (drop): Dropout(p=0.0, inplace=False)\n          )\n          (norm_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n        )\n        (11): BlockWithMasking(\n          (attn): MultiheadAttention(\n            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n          )\n          (drop_path): Identity()\n          (norm_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n          (mlp): Mlp(\n            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n            (act): GELU(approximate='none')\n            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n            (drop): Dropout(p=0.0, inplace=False)\n          )\n          (norm_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n        )\n      )\n      (post_transformer_layer): EinOpsRearrange()\n    )\n    (imu): SimpleTransformer(\n      (pre_transformer_layer): Sequential(\n        (0): Identity()\n        (1): EinOpsRearrange()\n      )\n      (blocks): Sequential(\n        (0): BlockWithMasking(\n          (attn): MultiheadAttention(\n            (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n          )\n          (drop_path): Identity()\n          (norm_1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n          (mlp): Mlp(\n            (fc1): Linear(in_features=512, out_features=2048, bias=True)\n            (act): GELU(approximate='none')\n            (fc2): Linear(in_features=2048, out_features=512, bias=True)\n            (drop): Dropout(p=0.0, inplace=False)\n          )\n          (norm_2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n        )\n        (1): BlockWithMasking(\n          (attn): MultiheadAttention(\n            (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n          )\n          (drop_path): DropPath(drop_prob=0.140)\n          (norm_1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n          (mlp): Mlp(\n            (fc1): Linear(in_features=512, out_features=2048, bias=True)\n            (act): GELU(approximate='none')\n            (fc2): Linear(in_features=2048, out_features=512, bias=True)\n            (drop): Dropout(p=0.0, inplace=False)\n          )\n          (norm_2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n        )\n        (2): BlockWithMasking(\n          (attn): MultiheadAttention(\n            (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n          )\n          (drop_path): DropPath(drop_prob=0.280)\n          (norm_1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n          (mlp): Mlp(\n            (fc1): Linear(in_features=512, out_features=2048, bias=True)\n            (act): GELU(approximate='none')\n            (fc2): Linear(in_features=2048, out_features=512, bias=True)\n            (drop): Dropout(p=0.0, inplace=False)\n          )\n          (norm_2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n        )\n        (3): BlockWithMasking(\n          (attn): MultiheadAttention(\n            (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n          )\n          (drop_path): DropPath(drop_prob=0.420)\n          (norm_1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n          (mlp): Mlp(\n            (fc1): Linear(in_features=512, out_features=2048, bias=True)\n            (act): GELU(approximate='none')\n            (fc2): Linear(in_features=2048, out_features=512, bias=True)\n            (drop): Dropout(p=0.0, inplace=False)\n          )\n          (norm_2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n        )\n        (4): BlockWithMasking(\n          (attn): MultiheadAttention(\n            (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n          )\n          (drop_path): DropPath(drop_prob=0.560)\n          (norm_1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n          (mlp): Mlp(\n            (fc1): Linear(in_features=512, out_features=2048, bias=True)\n            (act): GELU(approximate='none')\n            (fc2): Linear(in_features=2048, out_features=512, bias=True)\n            (drop): Dropout(p=0.0, inplace=False)\n          )\n          (norm_2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n        )\n        (5): BlockWithMasking(\n          (attn): MultiheadAttention(\n            (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n          )\n          (drop_path): DropPath(drop_prob=0.700)\n          (norm_1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n          (mlp): Mlp(\n            (fc1): Linear(in_features=512, out_features=2048, bias=True)\n            (act): GELU(approximate='none')\n            (fc2): Linear(in_features=2048, out_features=512, bias=True)\n            (drop): Dropout(p=0.0, inplace=False)\n          )\n          (norm_2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n        )\n      )\n      (post_transformer_layer): EinOpsRearrange()\n    )\n  )\n  (modality_heads): ModuleDict(\n    (vision): Sequential(\n      (0): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n      (1): SelectElement()\n      (2): Linear(in_features=1280, out_features=1024, bias=False)\n    )\n    (text): SelectEOSAndProject(\n      (proj): Sequential(\n        (0): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n        (1): Linear(in_features=1024, out_features=1024, bias=False)\n      )\n    )\n    (audio): Sequential(\n      (0): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n      (1): SelectElement()\n      (2): Linear(in_features=768, out_features=1024, bias=False)\n    )\n    (depth): Sequential(\n      (0): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n      (1): SelectElement()\n      (2): Linear(in_features=384, out_features=1024, bias=False)\n    )\n    (thermal): Sequential(\n      (0): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n      (1): SelectElement()\n      (2): Linear(in_features=768, out_features=1024, bias=False)\n    )\n    (imu): Sequential(\n      (0): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n      (1): SelectElement()\n      (2): Dropout(p=0.5, inplace=False)\n      (3): Linear(in_features=512, out_features=1024, bias=False)\n    )\n  )\n  (modality_postprocessors): ModuleDict(\n    (vision): Normalize()\n    (text): Sequential(\n      (0): Normalize()\n      (1): LearnableLogitScaling(logit_scale_init=14.285714285714285,learnable=True, max_logit_scale=100)\n    )\n    (audio): Sequential(\n      (0): Normalize()\n      (1): LearnableLogitScaling(logit_scale_init=20.0,learnable=False, max_logit_scale=100)\n    )\n    (depth): Sequential(\n      (0): Normalize()\n      (1): LearnableLogitScaling(logit_scale_init=5.0,learnable=False, max_logit_scale=100)\n    )\n    (thermal): Sequential(\n      (0): Normalize()\n      (1): LearnableLogitScaling(logit_scale_init=10.0,learnable=False, max_logit_scale=100)\n    )\n    (imu): Sequential(\n      (0): Normalize()\n      (1): LearnableLogitScaling(logit_scale_init=5.0,learnable=False, max_logit_scale=100)\n    )\n  )\n)"},"metadata":{}}],"execution_count":5}]}