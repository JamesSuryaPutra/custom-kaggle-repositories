{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":139474,"sourceType":"modelInstanceVersion","isSourceIdPinned":false,"modelInstanceId":118113,"modelId":141350}],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Preparation","metadata":{}},{"cell_type":"code","source":"# Install Ultralytics database\n%pip install ultralytics\nimport ultralytics\nultralytics.checks()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-14T05:45:19.346402Z","iopub.execute_input":"2025-03-14T05:45:19.346792Z","iopub.status.idle":"2025-03-14T05:45:30.262147Z","shell.execute_reply.started":"2025-03-14T05:45:19.346765Z","shell.execute_reply":"2025-03-14T05:45:30.261457Z"}},"outputs":[{"name":"stdout","text":"Ultralytics 8.3.89 ðŸš€ Python-3.10.12 torch-2.5.1+cu121 CUDA:0 (Tesla P100-PCIE-16GB, 16269MiB)\nSetup complete âœ… (4 CPUs, 31.4 GB RAM, 6170.0/8062.4 GB disk)\n","output_type":"stream"}],"execution_count":1},{"cell_type":"markdown","source":"## 1st step: Prediction","metadata":{}},{"cell_type":"code","source":"# Run inference on an image using YOLO11\n!yolo predict model=yolo11n.pt source='https://ultralytics.com/images/zidane.jpg'","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-14T05:45:30.263343Z","iopub.execute_input":"2025-03-14T05:45:30.263795Z","iopub.status.idle":"2025-03-14T05:45:39.446319Z","shell.execute_reply.started":"2025-03-14T05:45:30.263772Z","shell.execute_reply":"2025-03-14T05:45:39.445275Z"}},"outputs":[{"name":"stdout","text":"Downloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolo11n.pt to 'yolo11n.pt'...\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5.35M/5.35M [00:00<00:00, 103MB/s]\nUltralytics 8.3.89 ðŸš€ Python-3.10.12 torch-2.5.1+cu121 CUDA:0 (Tesla P100-PCIE-16GB, 16269MiB)\nYOLO11n summary (fused): 100 layers, 2,616,248 parameters, 0 gradients, 6.5 GFLOPs\n\nDownloading https://ultralytics.com/images/zidane.jpg to 'zidane.jpg'...\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 49.2k/49.2k [00:00<00:00, 7.94MB/s]\nimage 1/1 /kaggle/working/zidane.jpg: 384x640 2 persons, 1 tie, 87.6ms\nSpeed: 10.3ms preprocess, 87.6ms inference, 268.5ms postprocess per image at shape (1, 3, 384, 640)\nResults saved to \u001b[1mruns/detect/predict\u001b[0m\nðŸ’¡ Learn more at https://docs.ultralytics.com/modes/predict\n","output_type":"stream"}],"execution_count":2},{"cell_type":"markdown","source":"## 2nd step: Validation","metadata":{}},{"cell_type":"code","source":"# Download COCO validation database\nimport torch\ntorch.hub.download_url_to_file('https://ultralytics.com/assets/coco2017val.zip', 'tmp.zip')\n!unzip -q tmp.zip -d datasets && rm tmp.zip","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-14T05:45:39.447984Z","iopub.execute_input":"2025-03-14T05:45:39.448264Z","iopub.status.idle":"2025-03-14T05:45:49.585779Z","shell.execute_reply.started":"2025-03-14T05:45:39.448241Z","shell.execute_reply":"2025-03-14T05:45:49.584751Z"}},"outputs":[{"name":"stderr","text":"100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 780M/780M [00:02<00:00, 309MB/s] \n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"# Validate YOLO11 on COCO8\n!yolo val model=yolo11n.pt data=coco8.yaml","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-14T05:45:49.587466Z","iopub.execute_input":"2025-03-14T05:45:49.587815Z","iopub.status.idle":"2025-03-14T05:46:05.114631Z","shell.execute_reply.started":"2025-03-14T05:45:49.587780Z","shell.execute_reply":"2025-03-14T05:46:05.113705Z"}},"outputs":[{"name":"stdout","text":"Ultralytics 8.3.89 ðŸš€ Python-3.10.12 torch-2.5.1+cu121 CUDA:0 (Tesla P100-PCIE-16GB, 16269MiB)\nYOLO11n summary (fused): 100 layers, 2,616,248 parameters, 0 gradients, 6.5 GFLOPs\n\nDataset 'coco8.yaml' images not found âš ï¸, missing path '/kaggle/working/datasets/coco8/images/val'\nDownloading https://ultralytics.com/assets/coco8.zip to '/kaggle/working/datasets/coco8.zip'...\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 433k/433k [00:00<00:00, 19.9MB/s]\nUnzipping /kaggle/working/datasets/coco8.zip to /kaggle/working/datasets/coco8..\nDataset download success âœ… (0.7s), saved to \u001b[1m/kaggle/working/datasets\u001b[0m\n\nDownloading https://ultralytics.com/assets/Arial.ttf to '/root/.config/Ultralytics/Arial.ttf'...\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 755k/755k [00:00<00:00, 26.0MB/s]\n\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/datasets/coco8/labels/val... 4 images, 0 backgroun\u001b[0m\n\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /kaggle/working/datasets/coco8/labels/val.cache\n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all          4         17       0.57       0.85      0.847      0.632\n                person          3         10      0.557        0.6      0.585      0.272\n                   dog          1          1      0.548          1      0.995      0.697\n                 horse          1          2      0.531          1      0.995      0.674\n              elephant          1          2      0.371        0.5      0.516      0.256\n              umbrella          1          1      0.569          1      0.995      0.995\n          potted plant          1          1      0.847          1      0.995      0.895\n/usr/local/lib/python3.10/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n  xa[xa < 0] = -1\n/usr/local/lib/python3.10/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n  xa[xa < 0] = -1\nSpeed: 1.2ms preprocess, 14.9ms inference, 0.0ms loss, 35.5ms postprocess per image\nResults saved to \u001b[1mruns/detect/val\u001b[0m\nðŸ’¡ Learn more at https://docs.ultralytics.com/modes/val\n","output_type":"stream"}],"execution_count":4},{"cell_type":"markdown","source":"## 3rd step: Train","metadata":{}},{"cell_type":"code","source":"logger = 'Comet'\n\nif logger == 'Comet':\n    %pip install -q comet_ml\n    import comet_ml; comet_ml.login()\nelif logger == 'TensorBoard':\n    %load_ext tensorboard\n    %tensorboard --logdir .","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-14T05:46:05.115614Z","iopub.execute_input":"2025-03-14T05:46:05.115879Z","iopub.status.idle":"2025-03-14T05:46:36.144856Z","shell.execute_reply.started":"2025-03-14T05:46:05.115855Z","shell.execute_reply":"2025-03-14T05:46:36.144165Z"}},"outputs":[{"name":"stdout","text":"\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m725.8/725.8 kB\u001b[0m \u001b[31m16.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m45.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m79.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m138.0/138.0 kB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hNote: you may need to restart the kernel to use updated packages.\nPlease paste your Comet API key from https://www.comet.com/api/my/settings/\n(api key may not show as you type)\n","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"Comet API key:  Â·Â·Â·Â·Â·Â·Â·Â·\n"},{"name":"stderr","text":"\u001b[1;38;5;39mCOMET INFO:\u001b[0m Valid Comet API Key saved in /root/.comet.config (set COMET_CONFIG to change where it is saved).\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"# YOLO11 on COCO8 training (max. 3 epochs)\n!yolo train model=yolo11n.pt data=coco8.yaml epochs=3 imgsz=640","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-14T05:46:36.145864Z","iopub.execute_input":"2025-03-14T05:46:36.146209Z","iopub.status.idle":"2025-03-14T05:47:23.922835Z","shell.execute_reply.started":"2025-03-14T05:46:36.146175Z","shell.execute_reply":"2025-03-14T05:47:23.921993Z"}},"outputs":[{"name":"stdout","text":"Ultralytics 8.3.89 ðŸš€ Python-3.10.12 torch-2.5.1+cu121 CUDA:0 (Tesla P100-PCIE-16GB, 16269MiB)\n\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=detect, mode=train, model=yolo11n.pt, data=coco8.yaml, epochs=3, time=None, patience=100, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=None, workers=8, project=None, name=train, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=True, opset=None, workspace=None, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, copy_paste_mode=flip, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=runs/detect/train\n\n                   from  n    params  module                                       arguments                     \n  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n  2                  -1  1      6640  ultralytics.nn.modules.block.C3k2            [32, 64, 1, False, 0.25]      \n  3                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n  4                  -1  1     26080  ultralytics.nn.modules.block.C3k2            [64, 128, 1, False, 0.25]     \n  5                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n  6                  -1  1     87040  ultralytics.nn.modules.block.C3k2            [128, 128, 1, True]           \n  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n  8                  -1  1    346112  ultralytics.nn.modules.block.C3k2            [256, 256, 1, True]           \n  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n 10                  -1  1    249728  ultralytics.nn.modules.block.C2PSA           [256, 256, 1]                 \n 11                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n 12             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n 13                  -1  1    111296  ultralytics.nn.modules.block.C3k2            [384, 128, 1, False]          \n 14                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n 15             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n 16                  -1  1     32096  ultralytics.nn.modules.block.C3k2            [256, 64, 1, False]           \n 17                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n 18            [-1, 13]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n 19                  -1  1     86720  ultralytics.nn.modules.block.C3k2            [192, 128, 1, False]          \n 20                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n 21            [-1, 10]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n 22                  -1  1    378880  ultralytics.nn.modules.block.C3k2            [384, 256, 1, True]           \n 23        [16, 19, 22]  1    464912  ultralytics.nn.modules.head.Detect           [80, [64, 128, 256]]          \nYOLO11n summary: 181 layers, 2,624,080 parameters, 2,624,064 gradients, 6.6 GFLOPs\n\nTransferred 499/499 items from pretrained weights\n\u001b[1;38;5;214mCOMET WARNING:\u001b[0m To get all data logged automatically, import comet_ml before the following modules: torch.\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m Experiment is live on comet.com \u001b[38;5;39mhttps://www.comet.com/jamessuryaputra/general/ae7f525064da4d01835b03f1725a2631\u001b[0m\n\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m Couldn't find a Git repository in '/kaggle/working' nor in any parent directory. Set `COMET_GIT_DIRECTORY` if your Git Repository is elsewhere.\n\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/detect/train', view at http://localhost:6006/\nFreezing layer 'model.23.dfl.conv.weight'\n\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/datasets/coco8/labels/train... 4 images, 0 backg\u001b[0m\n\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/datasets/coco8/labels/train.cache\n/usr/local/lib/python3.10/dist-packages/albumentations/__init__.py:24: UserWarning: A new version of Albumentations is available: 2.0.5 (you have 1.4.20). Upgrade using: pip install -U albumentations. To disable automatic update checks, set the environment variable NO_ALBUMENTATIONS_UPDATE to 1.\n  check_for_updates()\n\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, num_output_channels=3, method='weighted_average'), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/datasets/coco8/labels/val.cache... 4 images, 0 bac\u001b[0m\nPlotting labels to runs/detect/train/labels.jpg... \n\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.000119, momentum=0.9) with parameter groups 81 weight(decay=0.0), 88 weight(decay=0.0005), 87 bias(decay=0.0)\n\u001b[34m\u001b[1mTensorBoard: \u001b[0mmodel graph visualization added âœ…\nImage sizes 640 train, 640 val\nUsing 4 dataloader workers\nLogging results to \u001b[1mruns/detect/train\u001b[0m\nStarting training for 3 epochs...\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n        1/3     0.844G     0.9637      3.269      1.333         30        640: 1\n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all          4         17      0.578       0.85      0.849      0.631\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n        2/3     0.844G      1.316      3.968      1.615         35        640: 1\n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all          4         17      0.581       0.85      0.851      0.613\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n        3/3     0.844G      1.434      3.932      1.811         15        640: 1\n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all          4         17      0.575       0.85      0.856      0.631\n\n3 epochs completed in 0.002 hours.\nOptimizer stripped from runs/detect/train/weights/last.pt, 5.5MB\nOptimizer stripped from runs/detect/train/weights/best.pt, 5.5MB\n\nValidating runs/detect/train/weights/best.pt...\nUltralytics 8.3.89 ðŸš€ Python-3.10.12 torch-2.5.1+cu121 CUDA:0 (Tesla P100-PCIE-16GB, 16269MiB)\nYOLO11n summary (fused): 100 layers, 2,616,248 parameters, 0 gradients, 6.5 GFLOPs\n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all          4         17      0.578       0.85      0.856      0.633\n                person          3         10      0.572        0.6      0.625      0.277\n                   dog          1          1      0.548          1      0.995      0.796\n                 horse          1          2      0.564          1      0.995      0.674\n              elephant          1          2      0.361        0.5      0.528      0.261\n              umbrella          1          1       0.57          1      0.995      0.895\n          potted plant          1          1      0.853          1      0.995      0.895\n/usr/local/lib/python3.10/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n  xa[xa < 0] = -1\n/usr/local/lib/python3.10/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n  xa[xa < 0] = -1\nSpeed: 0.2ms preprocess, 3.0ms inference, 0.0ms loss, 0.8ms postprocess per image\nResults saved to \u001b[1mruns/detect/train\u001b[0m\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m ---------------------------------------------------------------------------------------\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m Comet.ml Experiment Summary\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m ---------------------------------------------------------------------------------------\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m   Data:\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     display_summary_level : 1\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     name                  : spare_tortoise_1770\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     url                   : \u001b[38;5;39mhttps://www.comet.com/jamessuryaputra/general/ae7f525064da4d01835b03f1725a2631\u001b[0m\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m   Metrics [count] (min, max):\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     lr/pg0 [7]               : (0.0, 8.092e-07)\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     lr/pg1 [7]               : (0.0, 8.092e-07)\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     lr/pg2 [7]               : (0.0, 8.092e-07)\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     metrics/mAP50(B) [8]     : (0.84889, 0.85565)\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     metrics/mAP50-95(B) [8]  : (0.61315, 0.6332009154276238)\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     metrics/precision(B) [8] : (0.57544, 0.58079)\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     metrics/recall(B)        : 0.85\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     model/GFLOPs             : 6.614\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     model/parameters         : 2624080\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     model/speed_PyTorch(ms)  : 24.868\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     train/box_loss [6]       : (0.96367, 1.43397)\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     train/cls_loss [6]       : (3.26884, 3.96837)\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     train/dfl_loss [6]       : (1.33291, 1.81092)\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     val/box_loss [6]         : (1.65213, 1.67996)\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     val/cls_loss [6]         : (1.00922, 1.0299)\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     val/dfl_loss [6]         : (1.37798, 1.38537)\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m   Others:\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     eval_batch_logging_interval  : 1\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     log_confusion_matrix_on_eval : False\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     log_image_predictions        : True\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     max_image_predictions        : 100\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m   Parameters:\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     agnostic_nms    : False\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     amp             : True\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     augment         : False\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     auto_augment    : randaugment\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     batch           : 16\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     bgr             : 0.0\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     box             : 7.5\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     cache           : False\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     cfg             : None\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     classes         : None\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     close_mosaic    : 10\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     cls             : 0.5\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     conf            : None\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     copy_paste      : 0.0\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     copy_paste_mode : flip\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     cos_lr          : False\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     crop_fraction   : 1.0\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     data            : /usr/local/lib/python3.10/dist-packages/ultralytics/cfg/datasets/coco8.yaml\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     degrees         : 0.0\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     deterministic   : True\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     device          : None\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     dfl             : 1.5\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     dnn             : False\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     dropout         : 0.0\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     dynamic         : False\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     embed           : None\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     epochs          : 3\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     erasing         : 0.4\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     exist_ok        : False\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     fliplr          : 0.5\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     flipud          : 0.0\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     format          : torchscript\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     fraction        : 1.0\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     freeze          : None\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     half            : False\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     hsv_h           : 0.015\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     hsv_s           : 0.7\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     hsv_v           : 0.4\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     imgsz           : 640\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     int8            : False\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     iou             : 0.7\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     keras           : False\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     kobj            : 1.0\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     line_width      : None\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     lr0             : 0.01\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     lrf             : 0.01\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     mask_ratio      : 4\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     max_det         : 300\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     mixup           : 0.0\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     mode            : train\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     model           : yolo11n.pt\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     momentum        : 0.937\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     mosaic          : 1.0\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     multi_scale     : False\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     name            : train\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     nbs             : 64\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     nms             : False\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     opset           : None\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     optimize        : False\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     optimizer       : auto\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     overlap_mask    : True\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     patience        : 100\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     perspective     : 0.0\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     plots           : True\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     pose            : 12.0\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     pretrained      : True\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     profile         : False\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     project         : None\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     rect            : False\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     resume          : False\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     retina_masks    : False\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     save            : True\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     save_conf       : False\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     save_crop       : False\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     save_dir        : runs/detect/train\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     save_frames     : False\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     save_hybrid     : False\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     save_json       : False\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     save_period     : -1\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     save_txt        : False\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     scale           : 0.5\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     seed            : 0\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     shear           : 0.0\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     show            : False\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     show_boxes      : True\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     show_conf       : True\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     show_labels     : True\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     simplify        : True\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     single_cls      : False\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     source          : None\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     split           : val\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     stream_buffer   : False\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     task            : detect\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     time            : None\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     tracker         : botsort.yaml\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     translate       : 0.1\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     val             : True\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     verbose         : True\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     vid_stride      : 1\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     visualize       : False\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     warmup_bias_lr  : 0.1\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     warmup_epochs   : 3.0\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     warmup_momentum : 0.8\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     weight_decay    : 0.0005\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     workers         : 8\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     workspace       : None\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m   Uploads:\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     confusion-matrix    : 1\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     environment details : 1\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     filename            : 1\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     images              : 13\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     installed packages  : 1\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     model-element       : 1 (5.28 MB)\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     os packages         : 1\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     source_code         : 2 (17.18 KB)\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m \n\u001b[1;38;5;214mCOMET WARNING:\u001b[0m To get all data logged automatically, import comet_ml before the following modules: torch.\nðŸ’¡ Learn more at https://docs.ultralytics.com/modes/train\n","output_type":"stream"}],"execution_count":6},{"cell_type":"markdown","source":"## 4th step: Export","metadata":{}},{"cell_type":"code","source":"!yolo export model=yolo11n.pt format=torchscript","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-14T05:47:23.923739Z","iopub.execute_input":"2025-03-14T05:47:23.923977Z","iopub.status.idle":"2025-03-14T05:47:31.217840Z","shell.execute_reply.started":"2025-03-14T05:47:23.923955Z","shell.execute_reply":"2025-03-14T05:47:31.216969Z"}},"outputs":[{"name":"stdout","text":"Ultralytics 8.3.89 ðŸš€ Python-3.10.12 torch-2.5.1+cu121 CPU (Intel Xeon 2.00GHz)\nYOLO11n summary (fused): 100 layers, 2,616,248 parameters, 0 gradients, 6.5 GFLOPs\n\n\u001b[34m\u001b[1mPyTorch:\u001b[0m starting from 'yolo11n.pt' with input shape (1, 3, 640, 640) BCHW and output shape(s) (1, 84, 8400) (5.4 MB)\n\n\u001b[34m\u001b[1mTorchScript:\u001b[0m starting export with torch 2.5.1+cu121...\n\u001b[34m\u001b[1mTorchScript:\u001b[0m export success âœ… 2.0s, saved as 'yolo11n.torchscript' (10.5 MB)\n\nExport complete (3.8s)\nResults saved to \u001b[1m/kaggle/working\u001b[0m\nPredict:         yolo predict task=detect model=yolo11n.torchscript imgsz=640  \nValidate:        yolo val task=detect model=yolo11n.torchscript imgsz=640 data=/usr/src/ultralytics/ultralytics/cfg/datasets/coco.yaml  \nVisualize:       https://netron.app\nðŸ’¡ Learn more at https://docs.ultralytics.com/modes/export\n","output_type":"stream"}],"execution_count":7},{"cell_type":"markdown","source":"# Python Usage","metadata":{}},{"cell_type":"code","source":"from ultralytics import YOLO\n\n# Load a model\nmodel = YOLO('yolo11n.yaml')\nmodel = YOLO('yolo11n.pt')\n\n# Use the model\nresults = model.train(data='coco8.yaml', epochs=3)\nresults = model.val()\nresults = model('https://ultralytics.com/images/bus.jpg')\nresults = model.export(format='onnx')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-14T05:47:31.220089Z","iopub.execute_input":"2025-03-14T05:47:31.220326Z","iopub.status.idle":"2025-03-14T05:48:22.486977Z","shell.execute_reply.started":"2025-03-14T05:47:31.220305Z","shell.execute_reply":"2025-03-14T05:48:22.485985Z"}},"outputs":[{"name":"stdout","text":"Ultralytics 8.3.89 ðŸš€ Python-3.10.12 torch-2.5.1+cu121 CUDA:0 (Tesla P100-PCIE-16GB, 16269MiB)\n\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=detect, mode=train, model=yolo11n.pt, data=coco8.yaml, epochs=3, time=None, patience=100, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=None, workers=8, project=None, name=train2, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=True, opset=None, workspace=None, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, copy_paste_mode=flip, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=runs/detect/train2\n\n                   from  n    params  module                                       arguments                     \n  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n  2                  -1  1      6640  ultralytics.nn.modules.block.C3k2            [32, 64, 1, False, 0.25]      \n  3                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n  4                  -1  1     26080  ultralytics.nn.modules.block.C3k2            [64, 128, 1, False, 0.25]     \n  5                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n  6                  -1  1     87040  ultralytics.nn.modules.block.C3k2            [128, 128, 1, True]           \n  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n  8                  -1  1    346112  ultralytics.nn.modules.block.C3k2            [256, 256, 1, True]           \n  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n 10                  -1  1    249728  ultralytics.nn.modules.block.C2PSA           [256, 256, 1]                 \n 11                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n 12             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n 13                  -1  1    111296  ultralytics.nn.modules.block.C3k2            [384, 128, 1, False]          \n 14                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n 15             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n 16                  -1  1     32096  ultralytics.nn.modules.block.C3k2            [256, 64, 1, False]           \n 17                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n 18            [-1, 13]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n 19                  -1  1     86720  ultralytics.nn.modules.block.C3k2            [192, 128, 1, False]          \n 20                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n 21            [-1, 10]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n 22                  -1  1    378880  ultralytics.nn.modules.block.C3k2            [384, 256, 1, True]           \n 23        [16, 19, 22]  1    464912  ultralytics.nn.modules.head.Detect           [80, [64, 128, 256]]          \nYOLO11n summary: 181 layers, 2,624,080 parameters, 2,624,064 gradients, 6.6 GFLOPs\n\nTransferred 499/499 items from pretrained weights\n","output_type":"stream"},{"name":"stderr","text":"\u001b[1;38;5;214mCOMET WARNING:\u001b[0m To get all data logged automatically, import comet_ml before the following modules: torch.\n\u001b[1;38;5;214mCOMET WARNING:\u001b[0m As you are running in a Jupyter environment, you will need to call `experiment.end()` when finished to ensure all metrics and code are logged before exiting.\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m Experiment is live on comet.com https://www.comet.com/jamessuryaputra/general/ad32eecff9294ee680ba1766c6e06a47\n\n","output_type":"stream"},{"name":"stdout","text":"\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/detect/train2', view at http://localhost:6006/\n","output_type":"stream"},{"name":"stderr","text":"\u001b[1;38;5;39mCOMET INFO:\u001b[0m Couldn't find a Git repository in '/kaggle/working' nor in any parent directory. Set `COMET_GIT_DIRECTORY` if your Git Repository is elsewhere.\n","output_type":"stream"},{"name":"stdout","text":"Freezing layer 'model.23.dfl.conv.weight'\n\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/datasets/coco8/labels/train.cache... 4 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<?, ?it/s]\n","output_type":"stream"},{"name":"stdout","text":"\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, num_output_channels=3, method='weighted_average'), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/albumentations/__init__.py:24: UserWarning: A new version of Albumentations is available: 2.0.5 (you have 1.4.20). Upgrade using: pip install -U albumentations. To disable automatic update checks, set the environment variable NO_ALBUMENTATIONS_UPDATE to 1.\n  check_for_updates()\n\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/datasets/coco8/labels/val.cache... 4 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<?, ?it/s]\n","output_type":"stream"},{"name":"stdout","text":"Plotting labels to runs/detect/train2/labels.jpg... \n\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.000119, momentum=0.9) with parameter groups 81 weight(decay=0.0), 88 weight(decay=0.0005), 87 bias(decay=0.0)\n\u001b[34m\u001b[1mTensorBoard: \u001b[0mmodel graph visualization added âœ…\nImage sizes 640 train, 640 val\nUsing 4 dataloader workers\nLogging results to \u001b[1mruns/detect/train2\u001b[0m\nStarting training for 3 epochs...\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"        1/3     0.844G     0.9637      3.269      1.333         30        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.87it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  7.57it/s]","output_type":"stream"},{"name":"stdout","text":"                   all          4         17      0.578       0.85      0.849      0.631\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"        2/3     0.854G      1.316      3.968      1.615         35        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  7.63it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 14.59it/s]","output_type":"stream"},{"name":"stdout","text":"                   all          4         17      0.581       0.85      0.851      0.613\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"        3/3     0.854G      1.434      3.932      1.811         15        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  7.30it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 15.80it/s]","output_type":"stream"},{"name":"stdout","text":"                   all          4         17      0.575       0.85      0.856      0.631\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n3 epochs completed in 0.002 hours.\nOptimizer stripped from runs/detect/train2/weights/last.pt, 5.5MB\nOptimizer stripped from runs/detect/train2/weights/best.pt, 5.5MB\n\nValidating runs/detect/train2/weights/best.pt...\nUltralytics 8.3.89 ðŸš€ Python-3.10.12 torch-2.5.1+cu121 CUDA:0 (Tesla P100-PCIE-16GB, 16269MiB)\nYOLO11n summary (fused): 100 layers, 2,616,248 parameters, 0 gradients, 6.5 GFLOPs\n","output_type":"stream"},{"name":"stderr","text":"                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 26.77it/s]\n","output_type":"stream"},{"name":"stdout","text":"                   all          4         17      0.578       0.85      0.856      0.633\n                person          3         10      0.572        0.6      0.625      0.277\n                   dog          1          1      0.548          1      0.995      0.796\n                 horse          1          2      0.564          1      0.995      0.674\n              elephant          1          2      0.361        0.5      0.528      0.261\n              umbrella          1          1       0.57          1      0.995      0.895\n          potted plant          1          1      0.853          1      0.995      0.895\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n  xa[xa < 0] = -1\n/usr/local/lib/python3.10/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n  xa[xa < 0] = -1\n","output_type":"stream"},{"name":"stdout","text":"Speed: 0.2ms preprocess, 3.1ms inference, 0.0ms loss, 1.4ms postprocess per image\nResults saved to \u001b[1mruns/detect/train2\u001b[0m\n","output_type":"stream"},{"name":"stderr","text":"\u001b[1;38;5;39mCOMET INFO:\u001b[0m ---------------------------------------------------------------------------------------\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m Comet.ml Experiment Summary\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m ---------------------------------------------------------------------------------------\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m   Data:\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     display_summary_level : 1\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     name                  : quiet_boar_2850\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     url                   : https://www.comet.com/jamessuryaputra/general/ad32eecff9294ee680ba1766c6e06a47\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m   Metrics [count] (min, max):\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     lr/pg0 [7]               : (0.0, 8.092e-07)\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     lr/pg1 [7]               : (0.0, 8.092e-07)\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     lr/pg2 [7]               : (0.0, 8.092e-07)\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     metrics/mAP50(B) [8]     : (0.84889, 0.85565)\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     metrics/mAP50-95(B) [8]  : (0.61315, 0.6332009154276238)\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     metrics/precision(B) [8] : (0.57544, 0.58079)\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     metrics/recall(B)        : 0.85\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     model/GFLOPs             : 6.614\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     model/parameters         : 2624080\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     model/speed_PyTorch(ms)  : 23.753\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     train/box_loss [6]       : (0.96367, 1.43397)\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     train/cls_loss [6]       : (3.26884, 3.96837)\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     train/dfl_loss [6]       : (1.33291, 1.81092)\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     val/box_loss [6]         : (1.65213, 1.67996)\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     val/cls_loss [6]         : (1.00922, 1.0299)\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     val/dfl_loss [6]         : (1.37798, 1.38537)\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m   Others:\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     eval_batch_logging_interval  : 1\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     log_confusion_matrix_on_eval : False\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     log_image_predictions        : True\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     max_image_predictions        : 100\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m   Parameters:\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     agnostic_nms    : False\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     amp             : True\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     augment         : False\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     auto_augment    : randaugment\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     batch           : 16\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     bgr             : 0.0\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     box             : 7.5\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     cache           : False\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     cfg             : None\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     classes         : None\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     close_mosaic    : 10\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     cls             : 0.5\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     conf            : None\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     copy_paste      : 0.0\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     copy_paste_mode : flip\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     cos_lr          : False\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     crop_fraction   : 1.0\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     data            : /usr/local/lib/python3.10/dist-packages/ultralytics/cfg/datasets/coco8.yaml\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     degrees         : 0.0\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     deterministic   : True\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     device          : None\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     dfl             : 1.5\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     dnn             : False\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     dropout         : 0.0\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     dynamic         : False\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     embed           : None\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     epochs          : 3\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     erasing         : 0.4\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     exist_ok        : False\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     fliplr          : 0.5\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     flipud          : 0.0\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     format          : torchscript\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     fraction        : 1.0\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     freeze          : None\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     half            : False\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     hsv_h           : 0.015\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     hsv_s           : 0.7\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     hsv_v           : 0.4\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     imgsz           : 640\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     int8            : False\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     iou             : 0.7\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     keras           : False\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     kobj            : 1.0\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     line_width      : None\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     lr0             : 0.01\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     lrf             : 0.01\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     mask_ratio      : 4\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     max_det         : 300\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     mixup           : 0.0\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     mode            : train\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     model           : yolo11n.pt\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     momentum        : 0.937\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     mosaic          : 1.0\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     multi_scale     : False\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     name            : train2\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     nbs             : 64\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     nms             : False\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     opset           : None\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     optimize        : False\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     optimizer       : auto\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     overlap_mask    : True\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     patience        : 100\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     perspective     : 0.0\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     plots           : True\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     pose            : 12.0\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     pretrained      : True\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     profile         : False\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     project         : None\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     rect            : False\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     resume          : False\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     retina_masks    : False\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     save            : True\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     save_conf       : False\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     save_crop       : False\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     save_dir        : runs/detect/train2\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     save_frames     : False\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     save_hybrid     : False\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     save_json       : False\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     save_period     : -1\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     save_txt        : False\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     scale           : 0.5\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     seed            : 0\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     shear           : 0.0\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     show            : False\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     show_boxes      : True\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     show_conf       : True\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     show_labels     : True\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     simplify        : True\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     single_cls      : False\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     source          : None\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     split           : val\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     stream_buffer   : False\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     task            : detect\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     time            : None\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     tracker         : botsort.yaml\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     translate       : 0.1\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     val             : True\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     verbose         : True\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     vid_stride      : 1\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     visualize       : False\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     warmup_bias_lr  : 0.1\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     warmup_epochs   : 3.0\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     warmup_momentum : 0.8\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     weight_decay    : 0.0005\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     workers         : 8\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     workspace       : None\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m   Uploads:\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     confusion-matrix    : 1\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     environment details : 1\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     filename            : 1\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     images              : 13\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     installed packages  : 1\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     model-element       : 1 (5.28 MB)\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     notebook            : 1\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     os packages         : 1\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     source_code         : 1\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m \n\u001b[1;38;5;214mCOMET WARNING:\u001b[0m To get all data logged automatically, import comet_ml before the following modules: torch.\n","output_type":"stream"},{"name":"stdout","text":"Ultralytics 8.3.89 ðŸš€ Python-3.10.12 torch-2.5.1+cu121 CUDA:0 (Tesla P100-PCIE-16GB, 16269MiB)\nYOLO11n summary (fused): 100 layers, 2,616,248 parameters, 0 gradients, 6.5 GFLOPs\n","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/datasets/coco8/labels/val.cache... 4 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<?, ?it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.32it/s]\n","output_type":"stream"},{"name":"stdout","text":"                   all          4         17      0.575       0.85      0.856      0.637\n                person          3         10       0.57        0.6      0.627      0.302\n                   dog          1          1      0.547          1      0.995      0.796\n                 horse          1          2      0.554          1      0.995      0.674\n              elephant          1          2       0.36        0.5      0.528      0.261\n              umbrella          1          1      0.569          1      0.995      0.895\n          potted plant          1          1      0.852          1      0.995      0.895\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n  xa[xa < 0] = -1\n/usr/local/lib/python3.10/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n  xa[xa < 0] = -1\n","output_type":"stream"},{"name":"stdout","text":"Speed: 0.3ms preprocess, 16.7ms inference, 0.0ms loss, 1.0ms postprocess per image\nResults saved to \u001b[1mruns/detect/train22\u001b[0m\n\nDownloading https://ultralytics.com/images/bus.jpg to 'bus.jpg'...\n","output_type":"stream"},{"name":"stderr","text":"100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 134k/134k [00:00<00:00, 11.1MB/s]","output_type":"stream"},{"name":"stdout","text":"image 1/1 /kaggle/working/bus.jpg: 640x480 4 persons, 1 bus, 41.5ms\nSpeed: 2.9ms preprocess, 41.5ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 480)\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"Ultralytics 8.3.89 ðŸš€ Python-3.10.12 torch-2.5.1+cu121 CPU (Intel Xeon 2.00GHz)\n\n\u001b[34m\u001b[1mPyTorch:\u001b[0m starting from 'runs/detect/train2/weights/best.pt' with input shape (1, 3, 640, 640) BCHW and output shape(s) (1, 84, 8400) (5.3 MB)\n\u001b[31m\u001b[1mrequirements:\u001b[0m Ultralytics requirements ['onnxslim', 'onnxruntime-gpu'] not found, attempting AutoUpdate...\nCollecting onnxslim\n  Downloading onnxslim-0.1.48-py3-none-any.whl.metadata (4.6 kB)\nCollecting onnxruntime-gpu\n  Downloading onnxruntime_gpu-1.21.0-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (4.8 kB)\nRequirement already satisfied: onnx in /usr/local/lib/python3.10/dist-packages (from onnxslim) (1.17.0)\nRequirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from onnxslim) (1.13.1)\nRequirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from onnxslim) (24.2)\nCollecting coloredlogs (from onnxruntime-gpu)\n  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl.metadata (12 kB)\nRequirement already satisfied: flatbuffers in /usr/local/lib/python3.10/dist-packages (from onnxruntime-gpu) (24.3.25)\nRequirement already satisfied: numpy>=1.21.6 in /usr/local/lib/python3.10/dist-packages (from onnxruntime-gpu) (1.26.4)\nRequirement already satisfied: protobuf in /usr/local/lib/python3.10/dist-packages (from onnxruntime-gpu) (3.20.3)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.10/dist-packages (from numpy>=1.21.6->onnxruntime-gpu) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.10/dist-packages (from numpy>=1.21.6->onnxruntime-gpu) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.10/dist-packages (from numpy>=1.21.6->onnxruntime-gpu) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.10/dist-packages (from numpy>=1.21.6->onnxruntime-gpu) (2025.0.1)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.10/dist-packages (from numpy>=1.21.6->onnxruntime-gpu) (2022.0.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.10/dist-packages (from numpy>=1.21.6->onnxruntime-gpu) (2.4.1)\nCollecting humanfriendly>=9.1 (from coloredlogs->onnxruntime-gpu)\n  Downloading humanfriendly-10.0-py2.py3-none-any.whl.metadata (9.2 kB)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->onnxslim) (1.3.0)\nRequirement already satisfied: intel-openmp>=2024 in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>=1.21.6->onnxruntime-gpu) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>=1.21.6->onnxruntime-gpu) (2022.0.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.10/dist-packages (from tbb==2022.*->mkl->numpy>=1.21.6->onnxruntime-gpu) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.10/dist-packages (from mkl_umath->numpy>=1.21.6->onnxruntime-gpu) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.10/dist-packages (from intel-openmp>=2024->mkl->numpy>=1.21.6->onnxruntime-gpu) (2024.2.0)\nDownloading onnxslim-0.1.48-py3-none-any.whl (142 kB)\n   â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 142.9/142.9 kB 8.7 MB/s eta 0:00:00\nDownloading onnxruntime_gpu-1.21.0-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (280.8 MB)\n   â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 280.8/280.8 MB 248.7 MB/s eta 0:00:00\nDownloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n   â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 46.0/46.0 kB 225.5 MB/s eta 0:00:00\nDownloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n   â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 86.8/86.8 kB 317.6 MB/s eta 0:00:00\nInstalling collected packages: humanfriendly, coloredlogs, onnxslim, onnxruntime-gpu\nSuccessfully installed coloredlogs-15.0.1 humanfriendly-10.0 onnxruntime-gpu-1.21.0 onnxslim-0.1.48\n\n\u001b[31m\u001b[1mrequirements:\u001b[0m AutoUpdate success âœ… 10.2s, installed 2 packages: ['onnxslim', 'onnxruntime-gpu']\n\u001b[31m\u001b[1mrequirements:\u001b[0m âš ï¸ \u001b[1mRestart runtime or rerun command for updates to take effect\u001b[0m\n\n\n\u001b[34m\u001b[1mONNX:\u001b[0m starting export with onnx 1.17.0 opset 19...\n\u001b[34m\u001b[1mONNX:\u001b[0m slimming with onnxslim 0.1.48...\n\u001b[34m\u001b[1mONNX:\u001b[0m export success âœ… 11.5s, saved as 'runs/detect/train2/weights/best.onnx' (10.2 MB)\n\nExport complete (13.0s)\nResults saved to \u001b[1m/kaggle/working/runs/detect/train2/weights\u001b[0m\nPredict:         yolo predict task=detect model=runs/detect/train2/weights/best.onnx imgsz=640  \nValidate:        yolo val task=detect model=runs/detect/train2/weights/best.onnx imgsz=640 data=/usr/local/lib/python3.10/dist-packages/ultralytics/cfg/datasets/coco8.yaml  \nVisualize:       https://netron.app\n","output_type":"stream"}],"execution_count":8},{"cell_type":"markdown","source":"# YOLO11 Tasks","metadata":{}},{"cell_type":"markdown","source":"## 1st task: Detection","metadata":{}},{"cell_type":"code","source":"# Load the model (yolo11n.pt) and train on COCO128 (for 3 epochs), then predict the image\nfrom ultralytics import YOLO\n\nmodel = YOLO('yolo11n.pt')\nmodel.train(data='coco8.yaml', epochs=3)\nmodel('https://ultralytics.com/images/bus.jpg')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-14T05:48:22.488686Z","iopub.execute_input":"2025-03-14T05:48:22.488953Z","iopub.status.idle":"2025-03-14T05:48:45.007458Z","shell.execute_reply.started":"2025-03-14T05:48:22.488931Z","shell.execute_reply":"2025-03-14T05:48:45.006723Z"}},"outputs":[{"name":"stdout","text":"Ultralytics 8.3.89 ðŸš€ Python-3.10.12 torch-2.5.1+cu121 CUDA:0 (Tesla P100-PCIE-16GB, 16269MiB)\n\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=detect, mode=train, model=yolo11n.pt, data=coco8.yaml, epochs=3, time=None, patience=100, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=None, workers=8, project=None, name=train3, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=True, opset=None, workspace=None, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, copy_paste_mode=flip, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=runs/detect/train3\n\n                   from  n    params  module                                       arguments                     \n  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n  2                  -1  1      6640  ultralytics.nn.modules.block.C3k2            [32, 64, 1, False, 0.25]      \n  3                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n  4                  -1  1     26080  ultralytics.nn.modules.block.C3k2            [64, 128, 1, False, 0.25]     \n  5                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n  6                  -1  1     87040  ultralytics.nn.modules.block.C3k2            [128, 128, 1, True]           \n  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n  8                  -1  1    346112  ultralytics.nn.modules.block.C3k2            [256, 256, 1, True]           \n  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n 10                  -1  1    249728  ultralytics.nn.modules.block.C2PSA           [256, 256, 1]                 \n 11                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n 12             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n 13                  -1  1    111296  ultralytics.nn.modules.block.C3k2            [384, 128, 1, False]          \n 14                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n 15             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n 16                  -1  1     32096  ultralytics.nn.modules.block.C3k2            [256, 64, 1, False]           \n 17                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n 18            [-1, 13]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n 19                  -1  1     86720  ultralytics.nn.modules.block.C3k2            [192, 128, 1, False]          \n 20                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n 21            [-1, 10]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n 22                  -1  1    378880  ultralytics.nn.modules.block.C3k2            [384, 256, 1, True]           \n 23        [16, 19, 22]  1    464912  ultralytics.nn.modules.head.Detect           [80, [64, 128, 256]]          \nYOLO11n summary: 181 layers, 2,624,080 parameters, 2,624,064 gradients, 6.6 GFLOPs\n\nTransferred 499/499 items from pretrained weights\n","output_type":"stream"},{"name":"stderr","text":"\u001b[1;38;5;214mCOMET WARNING:\u001b[0m To get all data logged automatically, import comet_ml before the following modules: torch.\n\u001b[1;38;5;214mCOMET WARNING:\u001b[0m As you are running in a Jupyter environment, you will need to call `experiment.end()` when finished to ensure all metrics and code are logged before exiting.\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m Experiment is live on comet.com https://www.comet.com/jamessuryaputra/general/565a2c8741424b8dabdd2d1bb41f52d6\n\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m Couldn't find a Git repository in '/kaggle/working' nor in any parent directory. Set `COMET_GIT_DIRECTORY` if your Git Repository is elsewhere.\n","output_type":"stream"},{"name":"stdout","text":"\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/detect/train3', view at http://localhost:6006/\nFreezing layer 'model.23.dfl.conv.weight'\n\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/datasets/coco8/labels/train.cache... 4 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<?, ?it/s]","output_type":"stream"},{"name":"stdout","text":"\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, num_output_channels=3, method='weighted_average'), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n","output_type":"stream"},{"name":"stderr","text":"\n\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/datasets/coco8/labels/val.cache... 4 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<?, ?it/s]\n","output_type":"stream"},{"name":"stdout","text":"Plotting labels to runs/detect/train3/labels.jpg... \n\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.000119, momentum=0.9) with parameter groups 81 weight(decay=0.0), 88 weight(decay=0.0005), 87 bias(decay=0.0)\n\u001b[34m\u001b[1mTensorBoard: \u001b[0mmodel graph visualization added âœ…\nImage sizes 640 train, 640 val\nUsing 4 dataloader workers\nLogging results to \u001b[1mruns/detect/train3\u001b[0m\nStarting training for 3 epochs...\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"        1/3     0.873G     0.9637      3.269      1.333         30        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  6.79it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 13.81it/s]","output_type":"stream"},{"name":"stdout","text":"                   all          4         17      0.578       0.85      0.849      0.631\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"        2/3     0.881G      1.316      3.968      1.615         35        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  7.64it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 15.90it/s]","output_type":"stream"},{"name":"stdout","text":"                   all          4         17      0.581       0.85      0.851      0.613\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"        3/3     0.881G      1.434      3.932      1.811         15        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  7.66it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 16.88it/s]","output_type":"stream"},{"name":"stdout","text":"                   all          4         17      0.575       0.85      0.856      0.631\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n3 epochs completed in 0.002 hours.\nOptimizer stripped from runs/detect/train3/weights/last.pt, 5.5MB\nOptimizer stripped from runs/detect/train3/weights/best.pt, 5.5MB\n\nValidating runs/detect/train3/weights/best.pt...\nUltralytics 8.3.89 ðŸš€ Python-3.10.12 torch-2.5.1+cu121 CUDA:0 (Tesla P100-PCIE-16GB, 16269MiB)\nYOLO11n summary (fused): 100 layers, 2,616,248 parameters, 0 gradients, 6.5 GFLOPs\n","output_type":"stream"},{"name":"stderr","text":"                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 26.89it/s]\n","output_type":"stream"},{"name":"stdout","text":"                   all          4         17      0.578       0.85      0.856      0.633\n                person          3         10      0.572        0.6      0.625      0.277\n                   dog          1          1      0.548          1      0.995      0.796\n                 horse          1          2      0.564          1      0.995      0.674\n              elephant          1          2      0.361        0.5      0.528      0.261\n              umbrella          1          1       0.57          1      0.995      0.895\n          potted plant          1          1      0.853          1      0.995      0.895\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n  xa[xa < 0] = -1\n/usr/local/lib/python3.10/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n  xa[xa < 0] = -1\n","output_type":"stream"},{"name":"stdout","text":"Speed: 0.2ms preprocess, 3.0ms inference, 0.0ms loss, 1.5ms postprocess per image\nResults saved to \u001b[1mruns/detect/train3\u001b[0m\n","output_type":"stream"},{"name":"stderr","text":"\u001b[1;38;5;39mCOMET INFO:\u001b[0m ---------------------------------------------------------------------------------------\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m Comet.ml Experiment Summary\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m ---------------------------------------------------------------------------------------\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m   Data:\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     display_summary_level : 1\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     name                  : cooperative_burbot_2076\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     url                   : https://www.comet.com/jamessuryaputra/general/565a2c8741424b8dabdd2d1bb41f52d6\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m   Metrics [count] (min, max):\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     lr/pg0 [7]               : (0.0, 8.092e-07)\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     lr/pg1 [7]               : (0.0, 8.092e-07)\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     lr/pg2 [7]               : (0.0, 8.092e-07)\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     metrics/mAP50(B) [8]     : (0.84889, 0.85565)\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     metrics/mAP50-95(B) [8]  : (0.61315, 0.6332009154276238)\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     metrics/precision(B) [8] : (0.57544, 0.58079)\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     metrics/recall(B)        : 0.85\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     model/GFLOPs             : 6.614\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     model/parameters         : 2624080\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     model/speed_PyTorch(ms)  : 6.55\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     train/box_loss [6]       : (0.96367, 1.43397)\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     train/cls_loss [6]       : (3.26884, 3.96837)\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     train/dfl_loss [6]       : (1.33291, 1.81092)\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     val/box_loss [6]         : (1.65213, 1.67996)\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     val/cls_loss [6]         : (1.00922, 1.0299)\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     val/dfl_loss [6]         : (1.37798, 1.38537)\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m   Others:\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     eval_batch_logging_interval  : 1\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     log_confusion_matrix_on_eval : False\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     log_image_predictions        : True\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     max_image_predictions        : 100\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m   Parameters:\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     agnostic_nms    : False\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     amp             : True\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     augment         : False\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     auto_augment    : randaugment\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     batch           : 16\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     bgr             : 0.0\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     box             : 7.5\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     cache           : False\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     cfg             : None\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     classes         : None\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     close_mosaic    : 10\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     cls             : 0.5\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     conf            : None\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     copy_paste      : 0.0\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     copy_paste_mode : flip\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     cos_lr          : False\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     crop_fraction   : 1.0\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     data            : /usr/local/lib/python3.10/dist-packages/ultralytics/cfg/datasets/coco8.yaml\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     degrees         : 0.0\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     deterministic   : True\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     device          : None\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     dfl             : 1.5\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     dnn             : False\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     dropout         : 0.0\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     dynamic         : False\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     embed           : None\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     epochs          : 3\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     erasing         : 0.4\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     exist_ok        : False\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     fliplr          : 0.5\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     flipud          : 0.0\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     format          : torchscript\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     fraction        : 1.0\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     freeze          : None\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     half            : False\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     hsv_h           : 0.015\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     hsv_s           : 0.7\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     hsv_v           : 0.4\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     imgsz           : 640\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     int8            : False\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     iou             : 0.7\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     keras           : False\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     kobj            : 1.0\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     line_width      : None\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     lr0             : 0.01\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     lrf             : 0.01\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     mask_ratio      : 4\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     max_det         : 300\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     mixup           : 0.0\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     mode            : train\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     model           : yolo11n.pt\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     momentum        : 0.937\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     mosaic          : 1.0\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     multi_scale     : False\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     name            : train3\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     nbs             : 64\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     nms             : False\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     opset           : None\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     optimize        : False\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     optimizer       : auto\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     overlap_mask    : True\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     patience        : 100\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     perspective     : 0.0\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     plots           : True\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     pose            : 12.0\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     pretrained      : True\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     profile         : False\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     project         : None\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     rect            : False\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     resume          : False\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     retina_masks    : False\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     save            : True\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     save_conf       : False\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     save_crop       : False\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     save_dir        : runs/detect/train3\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     save_frames     : False\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     save_hybrid     : False\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     save_json       : False\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     save_period     : -1\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     save_txt        : False\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     scale           : 0.5\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     seed            : 0\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     shear           : 0.0\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     show            : False\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     show_boxes      : True\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     show_conf       : True\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     show_labels     : True\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     simplify        : True\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     single_cls      : False\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     source          : None\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     split           : val\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     stream_buffer   : False\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     task            : detect\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     time            : None\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     tracker         : botsort.yaml\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     translate       : 0.1\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     val             : True\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     verbose         : True\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     vid_stride      : 1\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     visualize       : False\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     warmup_bias_lr  : 0.1\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     warmup_epochs   : 3.0\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     warmup_momentum : 0.8\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     weight_decay    : 0.0005\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     workers         : 8\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     workspace       : None\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m   Uploads:\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     confusion-matrix    : 1\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     environment details : 1\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     filename            : 1\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     images              : 13\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     installed packages  : 1\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     model-element       : 1 (5.28 MB)\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     notebook            : 1\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     os packages         : 1\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     source_code         : 1\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m \n\u001b[1;38;5;214mCOMET WARNING:\u001b[0m To get all data logged automatically, import comet_ml before the following modules: torch.\n","output_type":"stream"},{"name":"stdout","text":"\nFound https://ultralytics.com/images/bus.jpg locally at bus.jpg\nimage 1/1 /kaggle/working/bus.jpg: 640x480 4 persons, 1 bus, 9.7ms\nSpeed: 2.2ms preprocess, 9.7ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 480)\n","output_type":"stream"},{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"[ultralytics.engine.results.Results object with attributes:\n \n boxes: ultralytics.engine.results.Boxes object\n keypoints: None\n masks: None\n names: {0: 'person', 1: 'bicycle', 2: 'car', 3: 'motorcycle', 4: 'airplane', 5: 'bus', 6: 'train', 7: 'truck', 8: 'boat', 9: 'traffic light', 10: 'fire hydrant', 11: 'stop sign', 12: 'parking meter', 13: 'bench', 14: 'bird', 15: 'cat', 16: 'dog', 17: 'horse', 18: 'sheep', 19: 'cow', 20: 'elephant', 21: 'bear', 22: 'zebra', 23: 'giraffe', 24: 'backpack', 25: 'umbrella', 26: 'handbag', 27: 'tie', 28: 'suitcase', 29: 'frisbee', 30: 'skis', 31: 'snowboard', 32: 'sports ball', 33: 'kite', 34: 'baseball bat', 35: 'baseball glove', 36: 'skateboard', 37: 'surfboard', 38: 'tennis racket', 39: 'bottle', 40: 'wine glass', 41: 'cup', 42: 'fork', 43: 'knife', 44: 'spoon', 45: 'bowl', 46: 'banana', 47: 'apple', 48: 'sandwich', 49: 'orange', 50: 'broccoli', 51: 'carrot', 52: 'hot dog', 53: 'pizza', 54: 'donut', 55: 'cake', 56: 'chair', 57: 'couch', 58: 'potted plant', 59: 'bed', 60: 'dining table', 61: 'toilet', 62: 'tv', 63: 'laptop', 64: 'mouse', 65: 'remote', 66: 'keyboard', 67: 'cell phone', 68: 'microwave', 69: 'oven', 70: 'toaster', 71: 'sink', 72: 'refrigerator', 73: 'book', 74: 'clock', 75: 'vase', 76: 'scissors', 77: 'teddy bear', 78: 'hair drier', 79: 'toothbrush'}\n obb: None\n orig_img: array([[[119, 146, 172],\n         [121, 148, 174],\n         [122, 152, 177],\n         ...,\n         [161, 171, 188],\n         [160, 170, 187],\n         [160, 170, 187]],\n \n        [[120, 147, 173],\n         [122, 149, 175],\n         [123, 153, 178],\n         ...,\n         [161, 171, 188],\n         [160, 170, 187],\n         [160, 170, 187]],\n \n        [[123, 150, 176],\n         [124, 151, 177],\n         [125, 155, 180],\n         ...,\n         [161, 171, 188],\n         [160, 170, 187],\n         [160, 170, 187]],\n \n        ...,\n \n        [[183, 182, 186],\n         [179, 178, 182],\n         [180, 179, 183],\n         ...,\n         [121, 111, 117],\n         [113, 103, 109],\n         [115, 105, 111]],\n \n        [[165, 164, 168],\n         [173, 172, 176],\n         [187, 186, 190],\n         ...,\n         [102,  92,  98],\n         [101,  91,  97],\n         [103,  93,  99]],\n \n        [[123, 122, 126],\n         [145, 144, 148],\n         [176, 175, 179],\n         ...,\n         [ 95,  85,  91],\n         [ 96,  86,  92],\n         [ 98,  88,  94]]], dtype=uint8)\n orig_shape: (1080, 810)\n path: '/kaggle/working/bus.jpg'\n probs: None\n save_dir: 'runs/detect/train32'\n speed: {'preprocess': 2.2116470001947164, 'inference': 9.733252999922115, 'postprocess': 1.2978190000012546}]"},"metadata":{}}],"execution_count":9},{"cell_type":"markdown","source":"## 2nd task: Segmentation","metadata":{}},{"cell_type":"code","source":"# Load the model (yolo11n-seg) and train on COCO128 (for 3 epochs), then predict the image\nfrom ultralytics import YOLO\n\nmodel = YOLO('yolo11n-seg.pt')\nmodel.train(data='coco8-seg.yaml', epochs=3)\nmodel('https://ultralytics.com/images/bus.jpg')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-14T05:48:45.008391Z","iopub.execute_input":"2025-03-14T05:48:45.008679Z","iopub.status.idle":"2025-03-14T05:49:11.014478Z","shell.execute_reply.started":"2025-03-14T05:48:45.008648Z","shell.execute_reply":"2025-03-14T05:49:11.013674Z"}},"outputs":[{"name":"stdout","text":"Downloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolo11n-seg.pt to 'yolo11n-seg.pt'...\n","output_type":"stream"},{"name":"stderr","text":"100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5.90M/5.90M [00:00<00:00, 118MB/s]","output_type":"stream"},{"name":"stdout","text":"Ultralytics 8.3.89 ðŸš€ Python-3.10.12 torch-2.5.1+cu121 CUDA:0 (Tesla P100-PCIE-16GB, 16269MiB)\n\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=yolo11n-seg.pt, data=coco8-seg.yaml, epochs=3, time=None, patience=100, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=None, workers=8, project=None, name=train, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=True, opset=None, workspace=None, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, copy_paste_mode=flip, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n\nDataset 'coco8-seg.yaml' images not found âš ï¸, missing path '/kaggle/working/datasets/coco8-seg/images/val'\nDownloading https://ultralytics.com/assets/coco8-seg.zip to '/kaggle/working/datasets/coco8-seg.zip'...\n","output_type":"stream"},{"name":"stderr","text":"\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 439k/439k [00:00<00:00, 22.7MB/s]\nUnzipping /kaggle/working/datasets/coco8-seg.zip to /kaggle/working/datasets/coco8-seg...: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 25/25 [00:00<00:00, 4045.43file/s]","output_type":"stream"},{"name":"stdout","text":"Dataset download success âœ… (0.6s), saved to \u001b[1m/kaggle/working/datasets\u001b[0m\n\n\n                   from  n    params  module                                       arguments                     \n  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n  2                  -1  1      6640  ultralytics.nn.modules.block.C3k2            [32, 64, 1, False, 0.25]      \n  3                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n  4                  -1  1     26080  ultralytics.nn.modules.block.C3k2            [64, 128, 1, False, 0.25]     \n  5                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n  6                  -1  1     87040  ultralytics.nn.modules.block.C3k2            [128, 128, 1, True]           \n  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n  8                  -1  1    346112  ultralytics.nn.modules.block.C3k2            [256, 256, 1, True]           \n  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n 10                  -1  1    249728  ultralytics.nn.modules.block.C2PSA           [256, 256, 1]                 \n 11                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n 12             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n 13                  -1  1    111296  ultralytics.nn.modules.block.C3k2            [384, 128, 1, False]          \n 14                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n 15             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n 16                  -1  1     32096  ultralytics.nn.modules.block.C3k2            [256, 64, 1, False]           \n 17                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n 18            [-1, 13]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n 19                  -1  1     86720  ultralytics.nn.modules.block.C3k2            [192, 128, 1, False]          \n 20                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n 21            [-1, 10]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n 22                  -1  1    378880  ultralytics.nn.modules.block.C3k2            [384, 256, 1, True]           \n 23        [16, 19, 22]  1    717680  ultralytics.nn.modules.head.Segment          [80, 32, 64, [64, 128, 256]]  \n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"YOLO11n-seg summary: 203 layers, 2,876,848 parameters, 2,876,832 gradients, 10.5 GFLOPs\n\nTransferred 561/561 items from pretrained weights\n","output_type":"stream"},{"name":"stderr","text":"\u001b[1;38;5;214mCOMET WARNING:\u001b[0m To get all data logged automatically, import comet_ml before the following modules: torch.\n\u001b[1;38;5;214mCOMET WARNING:\u001b[0m As you are running in a Jupyter environment, you will need to call `experiment.end()` when finished to ensure all metrics and code are logged before exiting.\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m Experiment is live on comet.com https://www.comet.com/jamessuryaputra/general/4152ced0a1624bd88cbe259c850f66a8\n\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m Couldn't find a Git repository in '/kaggle/working' nor in any parent directory. Set `COMET_GIT_DIRECTORY` if your Git Repository is elsewhere.\n","output_type":"stream"},{"name":"stdout","text":"\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\nFreezing layer 'model.23.dfl.conv.weight'\n\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/datasets/coco8-seg/labels/train... 4 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 1032.95it/s]","output_type":"stream"},{"name":"stdout","text":"\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/datasets/coco8-seg/labels/train.cache\n\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, num_output_channels=3, method='weighted_average'), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n","output_type":"stream"},{"name":"stderr","text":"\n\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/datasets/coco8-seg/labels/val... 4 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 2815.91it/s]","output_type":"stream"},{"name":"stdout","text":"\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /kaggle/working/datasets/coco8-seg/labels/val.cache\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"Plotting labels to runs/segment/train/labels.jpg... \n\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.000119, momentum=0.9) with parameter groups 90 weight(decay=0.0), 101 weight(decay=0.0005), 100 bias(decay=0.0)\n\u001b[34m\u001b[1mTensorBoard: \u001b[0mmodel graph visualization added âœ…\nImage sizes 640 train, 640 val\nUsing 4 dataloader workers\nLogging results to \u001b[1mruns/segment/train\u001b[0m\nStarting training for 3 epochs...\n\n      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"        1/3      1.05G      1.027      2.636      3.345      1.307         30        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.58it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  6.94it/s]","output_type":"stream"},{"name":"stdout","text":"                   all          4         17      0.783      0.892      0.939      0.667      0.724      0.833      0.822      0.564\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"        2/3      1.06G       1.31      4.195      3.834      1.577         36        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  6.34it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 13.35it/s]","output_type":"stream"},{"name":"stdout","text":"                   all          4         17      0.778      0.898      0.941      0.668      0.718      0.838      0.822      0.567\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"        3/3      1.06G      1.195       2.81       3.54      1.489         16        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  6.75it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 11.15it/s]","output_type":"stream"},{"name":"stdout","text":"                   all          4         17      0.778        0.9       0.94      0.668      0.717      0.838      0.822      0.565\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n3 epochs completed in 0.002 hours.\nOptimizer stripped from runs/segment/train/weights/last.pt, 6.1MB\nOptimizer stripped from runs/segment/train/weights/best.pt, 6.1MB\n\nValidating runs/segment/train/weights/best.pt...\nUltralytics 8.3.89 ðŸš€ Python-3.10.12 torch-2.5.1+cu121 CUDA:0 (Tesla P100-PCIE-16GB, 16269MiB)\nYOLO11n-seg summary (fused): 113 layers, 2,868,664 parameters, 0 gradients, 10.4 GFLOPs\n","output_type":"stream"},{"name":"stderr","text":"                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 14.82it/s]\n","output_type":"stream"},{"name":"stdout","text":"                   all          4         17      0.779      0.896      0.941      0.668       0.72      0.836      0.822      0.567\n                person          3         10      0.721      0.518      0.668      0.309      0.721      0.518       0.62      0.263\n                   dog          1          1      0.741          1      0.995      0.895      0.741          1      0.995      0.895\n                 horse          1          2      0.617          1      0.995      0.565      0.617          1      0.828        0.2\n              elephant          1          2          1      0.857      0.995      0.348      0.643        0.5      0.501       0.25\n              umbrella          1          1       0.67          1      0.995      0.995       0.67          1      0.995      0.895\n          potted plant          1          1      0.927          1      0.995      0.895      0.927          1      0.995      0.895\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n  xa[xa < 0] = -1\n/usr/local/lib/python3.10/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n  xa[xa < 0] = -1\n","output_type":"stream"},{"name":"stdout","text":"Speed: 0.2ms preprocess, 5.6ms inference, 0.0ms loss, 1.4ms postprocess per image\nResults saved to \u001b[1mruns/segment/train\u001b[0m\n","output_type":"stream"},{"name":"stderr","text":"\u001b[1;38;5;39mCOMET INFO:\u001b[0m ---------------------------------------------------------------------------------------\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m Comet.ml Experiment Summary\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m ---------------------------------------------------------------------------------------\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m   Data:\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     display_summary_level : 1\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     name                  : binding_egret_961\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     url                   : https://www.comet.com/jamessuryaputra/general/4152ced0a1624bd88cbe259c850f66a8\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m   Metrics [count] (min, max):\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     lr/pg0 [7]               : (0.0, 8.092e-07)\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     lr/pg1 [7]               : (0.0, 8.092e-07)\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     lr/pg2 [7]               : (0.0, 8.092e-07)\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     metrics/mAP50(B) [8]     : (0.93911, 0.94056)\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     metrics/mAP50(M) [8]     : (0.82163, 0.8222768981809462)\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     metrics/mAP50-95(B) [8]  : (0.66678, 0.66836)\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     metrics/mAP50-95(M) [8]  : (0.56376, 0.56657)\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     metrics/precision(B) [8] : (0.77797, 0.78307)\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     metrics/precision(M) [8] : (0.7169, 0.72419)\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     metrics/recall(B) [8]    : (0.89221, 0.89958)\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     metrics/recall(M) [8]    : (0.83333, 0.83829)\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     model/GFLOPs             : 10.529\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     model/parameters         : 2876848\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     model/speed_PyTorch(ms)  : 13.871\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     train/box_loss [6]       : (1.02707, 1.31048)\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     train/cls_loss [6]       : (3.34484, 3.83374)\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     train/dfl_loss [6]       : (1.30749, 1.57716)\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     train/seg_loss [6]       : (2.63632, 4.19473)\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     val/box_loss [6]         : (1.53214, 1.53477)\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     val/cls_loss [6]         : (1.00771, 1.01398)\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     val/dfl_loss [6]         : (1.32413, 1.33646)\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     val/seg_loss [6]         : (2.51701, 2.52759)\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m   Others:\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     eval_batch_logging_interval  : 1\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     log_confusion_matrix_on_eval : False\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     log_image_predictions        : True\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     max_image_predictions        : 100\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m   Parameters:\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     agnostic_nms    : False\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     amp             : True\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     augment         : False\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     auto_augment    : randaugment\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     batch           : 16\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     bgr             : 0.0\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     box             : 7.5\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     cache           : False\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     cfg             : None\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     classes         : None\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     close_mosaic    : 10\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     cls             : 0.5\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     conf            : None\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     copy_paste      : 0.0\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     copy_paste_mode : flip\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     cos_lr          : False\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     crop_fraction   : 1.0\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     data            : /usr/local/lib/python3.10/dist-packages/ultralytics/cfg/datasets/coco8-seg.yaml\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     degrees         : 0.0\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     deterministic   : True\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     device          : None\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     dfl             : 1.5\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     dnn             : False\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     dropout         : 0.0\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     dynamic         : False\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     embed           : None\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     epochs          : 3\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     erasing         : 0.4\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     exist_ok        : False\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     fliplr          : 0.5\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     flipud          : 0.0\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     format          : torchscript\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     fraction        : 1.0\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     freeze          : None\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     half            : False\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     hsv_h           : 0.015\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     hsv_s           : 0.7\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     hsv_v           : 0.4\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     imgsz           : 640\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     int8            : False\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     iou             : 0.7\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     keras           : False\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     kobj            : 1.0\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     line_width      : None\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     lr0             : 0.01\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     lrf             : 0.01\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     mask_ratio      : 4\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     max_det         : 300\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     mixup           : 0.0\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     mode            : train\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     model           : yolo11n-seg.pt\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     momentum        : 0.937\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     mosaic          : 1.0\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     multi_scale     : False\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     name            : train\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     nbs             : 64\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     nms             : False\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     opset           : None\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     optimize        : False\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     optimizer       : auto\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     overlap_mask    : True\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     patience        : 100\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     perspective     : 0.0\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     plots           : True\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     pose            : 12.0\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     pretrained      : True\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     profile         : False\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     project         : None\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     rect            : False\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     resume          : False\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     retina_masks    : False\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     save            : True\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     save_conf       : False\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     save_crop       : False\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     save_dir        : runs/segment/train\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     save_frames     : False\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     save_hybrid     : False\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     save_json       : False\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     save_period     : -1\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     save_txt        : False\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     scale           : 0.5\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     seed            : 0\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     shear           : 0.0\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     show            : False\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     show_boxes      : True\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     show_conf       : True\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     show_labels     : True\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     simplify        : True\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     single_cls      : False\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     source          : None\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     split           : val\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     stream_buffer   : False\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     task            : segment\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     time            : None\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     tracker         : botsort.yaml\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     translate       : 0.1\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     val             : True\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     verbose         : True\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     vid_stride      : 1\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     visualize       : False\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     warmup_bias_lr  : 0.1\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     warmup_epochs   : 3.0\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     warmup_momentum : 0.8\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     weight_decay    : 0.0005\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     workers         : 8\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     workspace       : None\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m   Uploads:\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     confusion-matrix    : 1\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     environment details : 1\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     filename            : 1\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     images              : 17\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     installed packages  : 1\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     model-element       : 1 (5.79 MB)\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     notebook            : 1\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     os packages         : 1\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     source_code         : 1\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m \n\u001b[1;38;5;214mCOMET WARNING:\u001b[0m To get all data logged automatically, import comet_ml before the following modules: torch.\n","output_type":"stream"},{"name":"stdout","text":"\nFound https://ultralytics.com/images/bus.jpg locally at bus.jpg\nimage 1/1 /kaggle/working/bus.jpg: 640x480 4 persons, 1 bus, 1 stop sign, 18.5ms\nSpeed: 2.3ms preprocess, 18.5ms inference, 10.2ms postprocess per image at shape (1, 3, 640, 480)\n","output_type":"stream"},{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"[ultralytics.engine.results.Results object with attributes:\n \n boxes: ultralytics.engine.results.Boxes object\n keypoints: None\n masks: ultralytics.engine.results.Masks object\n names: {0: 'person', 1: 'bicycle', 2: 'car', 3: 'motorcycle', 4: 'airplane', 5: 'bus', 6: 'train', 7: 'truck', 8: 'boat', 9: 'traffic light', 10: 'fire hydrant', 11: 'stop sign', 12: 'parking meter', 13: 'bench', 14: 'bird', 15: 'cat', 16: 'dog', 17: 'horse', 18: 'sheep', 19: 'cow', 20: 'elephant', 21: 'bear', 22: 'zebra', 23: 'giraffe', 24: 'backpack', 25: 'umbrella', 26: 'handbag', 27: 'tie', 28: 'suitcase', 29: 'frisbee', 30: 'skis', 31: 'snowboard', 32: 'sports ball', 33: 'kite', 34: 'baseball bat', 35: 'baseball glove', 36: 'skateboard', 37: 'surfboard', 38: 'tennis racket', 39: 'bottle', 40: 'wine glass', 41: 'cup', 42: 'fork', 43: 'knife', 44: 'spoon', 45: 'bowl', 46: 'banana', 47: 'apple', 48: 'sandwich', 49: 'orange', 50: 'broccoli', 51: 'carrot', 52: 'hot dog', 53: 'pizza', 54: 'donut', 55: 'cake', 56: 'chair', 57: 'couch', 58: 'potted plant', 59: 'bed', 60: 'dining table', 61: 'toilet', 62: 'tv', 63: 'laptop', 64: 'mouse', 65: 'remote', 66: 'keyboard', 67: 'cell phone', 68: 'microwave', 69: 'oven', 70: 'toaster', 71: 'sink', 72: 'refrigerator', 73: 'book', 74: 'clock', 75: 'vase', 76: 'scissors', 77: 'teddy bear', 78: 'hair drier', 79: 'toothbrush'}\n obb: None\n orig_img: array([[[119, 146, 172],\n         [121, 148, 174],\n         [122, 152, 177],\n         ...,\n         [161, 171, 188],\n         [160, 170, 187],\n         [160, 170, 187]],\n \n        [[120, 147, 173],\n         [122, 149, 175],\n         [123, 153, 178],\n         ...,\n         [161, 171, 188],\n         [160, 170, 187],\n         [160, 170, 187]],\n \n        [[123, 150, 176],\n         [124, 151, 177],\n         [125, 155, 180],\n         ...,\n         [161, 171, 188],\n         [160, 170, 187],\n         [160, 170, 187]],\n \n        ...,\n \n        [[183, 182, 186],\n         [179, 178, 182],\n         [180, 179, 183],\n         ...,\n         [121, 111, 117],\n         [113, 103, 109],\n         [115, 105, 111]],\n \n        [[165, 164, 168],\n         [173, 172, 176],\n         [187, 186, 190],\n         ...,\n         [102,  92,  98],\n         [101,  91,  97],\n         [103,  93,  99]],\n \n        [[123, 122, 126],\n         [145, 144, 148],\n         [176, 175, 179],\n         ...,\n         [ 95,  85,  91],\n         [ 96,  86,  92],\n         [ 98,  88,  94]]], dtype=uint8)\n orig_shape: (1080, 810)\n path: '/kaggle/working/bus.jpg'\n probs: None\n save_dir: 'runs/segment/train2'\n speed: {'preprocess': 2.279737999970166, 'inference': 18.48084200014455, 'postprocess': 10.224940999933096}]"},"metadata":{}}],"execution_count":10},{"cell_type":"markdown","source":"## 3rd task: Classification","metadata":{}},{"cell_type":"code","source":"# Load the model (yolo11n-cls) and train on COCO128 (for 3 epochs), then predict the image\nfrom ultralytics import YOLO\n\nmodel = YOLO('yolo11n-cls.pt')\nmodel.train(data='mnist160', epochs=3)\nmodel('https://ultralytics.com/images/bus.jpg')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-14T05:49:11.015502Z","iopub.execute_input":"2025-03-14T05:49:11.015813Z","iopub.status.idle":"2025-03-14T05:49:23.990404Z","shell.execute_reply.started":"2025-03-14T05:49:11.015789Z","shell.execute_reply":"2025-03-14T05:49:23.989496Z"}},"outputs":[{"name":"stdout","text":"Downloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolo11n-cls.pt to 'yolo11n-cls.pt'...\n","output_type":"stream"},{"name":"stderr","text":"100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5.52M/5.52M [00:00<00:00, 110MB/s]","output_type":"stream"},{"name":"stdout","text":"Ultralytics 8.3.89 ðŸš€ Python-3.10.12 torch-2.5.1+cu121 CUDA:0 (Tesla P100-PCIE-16GB, 16269MiB)\n\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=classify, mode=train, model=yolo11n-cls.pt, data=mnist160, epochs=3, time=None, patience=100, batch=16, imgsz=224, save=True, save_period=-1, cache=False, device=None, workers=8, project=None, name=train, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=True, opset=None, workspace=None, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, copy_paste_mode=flip, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=runs/classify/train\n\nDataset not found âš ï¸, missing path /kaggle/working/datasets/mnist160, attempting download...\nDownloading https://ultralytics.com/assets/mnist160.zip to '/kaggle/working/datasets/mnist160.zip'...\n","output_type":"stream"},{"name":"stderr","text":"\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 70.0k/70.0k [00:00<00:00, 8.74MB/s]\nUnzipping /kaggle/working/datasets/mnist160.zip to /kaggle/working/datasets/mnist160...: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 184/184 [00:00<00:00, 10637.08file/s]","output_type":"stream"},{"name":"stdout","text":"Dataset download success âœ… (0.7s), saved to \u001b[1m/kaggle/working/datasets/mnist160\u001b[0m\n\n\u001b[34m\u001b[1mtrain:\u001b[0m /kaggle/working/datasets/mnist160/train... found 80 images in 10 classes âœ… \n\u001b[34m\u001b[1mval:\u001b[0m None...\n\u001b[34m\u001b[1mtest:\u001b[0m /kaggle/working/datasets/mnist160/test... found 80 images in 10 classes âœ… \nOverriding model.yaml nc=80 with nc=10\n\n                   from  n    params  module                                       arguments                     \n  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n  2                  -1  1      6640  ultralytics.nn.modules.block.C3k2            [32, 64, 1, False, 0.25]      \n  3                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n  4                  -1  1     26080  ultralytics.nn.modules.block.C3k2            [64, 128, 1, False, 0.25]     \n  5                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n  6                  -1  1     87040  ultralytics.nn.modules.block.C3k2            [128, 128, 1, True]           \n  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n  8                  -1  1    346112  ultralytics.nn.modules.block.C3k2            [256, 256, 1, True]           \n  9                  -1  1    249728  ultralytics.nn.modules.block.C2PSA           [256, 256, 1]                 \n 10                  -1  1    343050  ultralytics.nn.modules.head.Classify         [256, 10]                     \nYOLO11n-cls summary: 86 layers, 1,543,914 parameters, 1,543,914 gradients, 3.3 GFLOPs\nTransferred 234/236 items from pretrained weights\n","output_type":"stream"},{"name":"stderr","text":"\n\u001b[1;38;5;214mCOMET WARNING:\u001b[0m To get all data logged automatically, import comet_ml before the following modules: torch.\n\u001b[1;38;5;214mCOMET WARNING:\u001b[0m As you are running in a Jupyter environment, you will need to call `experiment.end()` when finished to ensure all metrics and code are logged before exiting.\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m Experiment is live on comet.com https://www.comet.com/jamessuryaputra/general/c6b5f7dc9e314794b5fce2c2621636ee\n\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m Couldn't find a Git repository in '/kaggle/working' nor in any parent directory. Set `COMET_GIT_DIRECTORY` if your Git Repository is elsewhere.\n","output_type":"stream"},{"name":"stdout","text":"\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/classify/train', view at http://localhost:6006/\n\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/datasets/mnist160/train... 80 images, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 80/80 [00:00<00:00, 2614.31it/s]","output_type":"stream"},{"name":"stdout","text":"\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/datasets/mnist160/train.cache\n","output_type":"stream"},{"name":"stderr","text":"\n\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/datasets/mnist160/test... 80 images, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 80/80 [00:00<00:00, 2382.23it/s]","output_type":"stream"},{"name":"stdout","text":"\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /kaggle/working/datasets/mnist160/test.cache\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.000714, momentum=0.9) with parameter groups 39 weight(decay=0.0), 40 weight(decay=0.0005), 40 bias(decay=0.0)\n\u001b[34m\u001b[1mTensorBoard: \u001b[0mmodel graph visualization added âœ…\nImage sizes 224 train, 224 val\nUsing 4 dataloader workers\nLogging results to \u001b[1mruns/classify/train\u001b[0m\nStarting training for 3 epochs...\n\n      Epoch    GPU_mem       loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"        1/3     0.324G      2.509         16        224: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:00<00:00,  8.92it/s]\n               classes   top1_acc   top5_acc: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:00<00:00, 31.75it/s]","output_type":"stream"},{"name":"stdout","text":"                   all        0.1      0.488\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem       loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"        2/3     0.328G      2.422         16        224: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:00<00:00, 16.72it/s]\n               classes   top1_acc   top5_acc: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:00<00:00, 56.03it/s]","output_type":"stream"},{"name":"stdout","text":"                   all      0.138      0.475\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem       loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"        3/3     0.328G      2.383         16        224: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:00<00:00, 17.17it/s]\n               classes   top1_acc   top5_acc: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:00<00:00, 56.00it/s]","output_type":"stream"},{"name":"stdout","text":"                   all     0.0875      0.538\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n3 epochs completed in 0.001 hours.\nOptimizer stripped from runs/classify/train/weights/last.pt, 3.2MB\nOptimizer stripped from runs/classify/train/weights/best.pt, 3.2MB\n\nValidating runs/classify/train/weights/best.pt...\nUltralytics 8.3.89 ðŸš€ Python-3.10.12 torch-2.5.1+cu121 CUDA:0 (Tesla P100-PCIE-16GB, 16269MiB)\nYOLO11n-cls summary (fused): 47 layers, 1,538,834 parameters, 0 gradients, 3.2 GFLOPs\nWARNING âš ï¸ Dataset 'split=val' not found, using 'split=test' instead.\n\u001b[34m\u001b[1mtrain:\u001b[0m /kaggle/working/datasets/mnist160/train... found 80 images in 10 classes âœ… \n\u001b[34m\u001b[1mval:\u001b[0m None...\n\u001b[34m\u001b[1mtest:\u001b[0m /kaggle/working/datasets/mnist160/test... found 80 images in 10 classes âœ… \n","output_type":"stream"},{"name":"stderr","text":"               classes   top1_acc   top5_acc: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:00<00:00, 27.67it/s]\n/usr/local/lib/python3.10/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n  xa[xa < 0] = -1\n/usr/local/lib/python3.10/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n  xa[xa < 0] = -1\n","output_type":"stream"},{"name":"stdout","text":"                   all     0.0875      0.538\nSpeed: 0.1ms preprocess, 0.9ms inference, 0.0ms loss, 0.0ms postprocess per image\nResults saved to \u001b[1mruns/classify/train\u001b[0m\n","output_type":"stream"},{"name":"stderr","text":"\u001b[1;38;5;39mCOMET INFO:\u001b[0m ---------------------------------------------------------------------------------------\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m Comet.ml Experiment Summary\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m ---------------------------------------------------------------------------------------\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m   Data:\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     display_summary_level : 1\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     name                  : rear_transom_3582\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     url                   : https://www.comet.com/jamessuryaputra/general/c6b5f7dc9e314794b5fce2c2621636ee\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m   Metrics [count] (min, max):\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     lr/pg0 [7]                : (2.856e-05, 4.3054200000000005e-05)\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     lr/pg1 [7]                : (2.856e-05, 4.3054200000000005e-05)\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     lr/pg2 [7]                : (2.856e-05, 4.3054200000000005e-05)\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     metrics/accuracy_top1 [8] : (0.08749999850988388, 0.1375)\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     metrics/accuracy_top5 [8] : (0.475, 0.5375000238418579)\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     model/GFLOPs              : 3.263\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     model/parameters          : 1543914\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     model/speed_PyTorch(ms)   : 1.076\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     train/loss [6]            : (2.38268, 2.50884)\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     val/loss [6]              : (2.3418, 2.41862)\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m   Others:\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     eval_batch_logging_interval  : 1\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     log_confusion_matrix_on_eval : False\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     log_image_predictions        : True\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     max_image_predictions        : 100\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m   Parameters:\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     agnostic_nms    : False\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     amp             : True\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     augment         : False\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     auto_augment    : randaugment\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     batch           : 16\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     bgr             : 0.0\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     box             : 7.5\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     cache           : False\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     cfg             : None\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     classes         : None\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     close_mosaic    : 10\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     cls             : 0.5\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     conf            : None\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     copy_paste      : 0.0\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     copy_paste_mode : flip\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     cos_lr          : False\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     crop_fraction   : 1.0\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     data            : mnist160\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     degrees         : 0.0\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     deterministic   : True\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     device          : None\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     dfl             : 1.5\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     dnn             : False\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     dropout         : 0.0\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     dynamic         : False\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     embed           : None\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     epochs          : 3\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     erasing         : 0.4\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     exist_ok        : False\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     fliplr          : 0.5\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     flipud          : 0.0\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     format          : torchscript\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     fraction        : 1.0\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     freeze          : None\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     half            : False\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     hsv_h           : 0.015\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     hsv_s           : 0.7\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     hsv_v           : 0.4\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     imgsz           : 224\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     int8            : False\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     iou             : 0.7\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     keras           : False\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     kobj            : 1.0\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     line_width      : None\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     lr0             : 0.01\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     lrf             : 0.01\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     mask_ratio      : 4\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     max_det         : 300\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     mixup           : 0.0\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     mode            : train\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     model           : yolo11n-cls.pt\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     momentum        : 0.937\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     mosaic          : 1.0\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     multi_scale     : False\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     name            : train\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     nbs             : 64\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     nms             : False\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     opset           : None\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     optimize        : False\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     optimizer       : auto\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     overlap_mask    : True\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     patience        : 100\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     perspective     : 0.0\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     plots           : True\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     pose            : 12.0\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     pretrained      : True\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     profile         : False\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     project         : None\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     rect            : False\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     resume          : False\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     retina_masks    : False\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     save            : True\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     save_conf       : False\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     save_crop       : False\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     save_dir        : runs/classify/train\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     save_frames     : False\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     save_hybrid     : False\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     save_json       : False\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     save_period     : -1\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     save_txt        : False\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     scale           : 0.5\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     seed            : 0\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     shear           : 0.0\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     show            : False\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     show_boxes      : True\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     show_conf       : True\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     show_labels     : True\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     simplify        : True\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     single_cls      : False\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     source          : None\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     split           : val\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     stream_buffer   : False\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     task            : classify\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     time            : None\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     tracker         : botsort.yaml\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     translate       : 0.1\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     val             : True\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     verbose         : True\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     vid_stride      : 1\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     visualize       : False\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     warmup_bias_lr  : 0.1\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     warmup_epochs   : 3.0\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     warmup_momentum : 0.8\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     weight_decay    : 0.0005\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     workers         : 8\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     workspace       : None\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m   Uploads:\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     confusion-matrix    : 1\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     environment details : 1\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     filename            : 1\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     images              : 11\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     installed packages  : 1\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     model-element       : 1 (3.06 MB)\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     notebook            : 1\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     os packages         : 1\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     source_code         : 1\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m \n\u001b[1;38;5;214mCOMET WARNING:\u001b[0m To get all data logged automatically, import comet_ml before the following modules: torch.\n","output_type":"stream"},{"name":"stdout","text":"\nFound https://ultralytics.com/images/bus.jpg locally at bus.jpg\nimage 1/1 /kaggle/working/bus.jpg: 224x224 6 0.35, 9 0.15, 5 0.14, 0 0.09, 8 0.08, 4.3ms\nSpeed: 13.4ms preprocess, 4.3ms inference, 0.1ms postprocess per image at shape (1, 3, 224, 224)\n","output_type":"stream"},{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"[ultralytics.engine.results.Results object with attributes:\n \n boxes: None\n keypoints: None\n masks: None\n names: {0: '0', 1: '1', 2: '2', 3: '3', 4: '4', 5: '5', 6: '6', 7: '7', 8: '8', 9: '9'}\n obb: None\n orig_img: array([[[119, 146, 172],\n         [121, 148, 174],\n         [122, 152, 177],\n         ...,\n         [161, 171, 188],\n         [160, 170, 187],\n         [160, 170, 187]],\n \n        [[120, 147, 173],\n         [122, 149, 175],\n         [123, 153, 178],\n         ...,\n         [161, 171, 188],\n         [160, 170, 187],\n         [160, 170, 187]],\n \n        [[123, 150, 176],\n         [124, 151, 177],\n         [125, 155, 180],\n         ...,\n         [161, 171, 188],\n         [160, 170, 187],\n         [160, 170, 187]],\n \n        ...,\n \n        [[183, 182, 186],\n         [179, 178, 182],\n         [180, 179, 183],\n         ...,\n         [121, 111, 117],\n         [113, 103, 109],\n         [115, 105, 111]],\n \n        [[165, 164, 168],\n         [173, 172, 176],\n         [187, 186, 190],\n         ...,\n         [102,  92,  98],\n         [101,  91,  97],\n         [103,  93,  99]],\n \n        [[123, 122, 126],\n         [145, 144, 148],\n         [176, 175, 179],\n         ...,\n         [ 95,  85,  91],\n         [ 96,  86,  92],\n         [ 98,  88,  94]]], dtype=uint8)\n orig_shape: (1080, 810)\n path: '/kaggle/working/bus.jpg'\n probs: ultralytics.engine.results.Probs object\n save_dir: 'runs/classify/train2'\n speed: {'preprocess': 13.392487999908553, 'inference': 4.310262999979386, 'postprocess': 0.11526499997671635}]"},"metadata":{}}],"execution_count":11},{"cell_type":"markdown","source":"## 4th step: Pose","metadata":{}},{"cell_type":"code","source":"# Load the model (yolo11n-pose) and train on COCO128 (for 3 epochs), then predict the image\nfrom ultralytics import YOLO\n\nmodel = YOLO('yolo11n-pose.pt')\nmodel.train(data='coco8-pose.yaml', epochs=3)\nmodel('https://ultralytics.com/images/bus.jpg')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-14T05:49:23.991441Z","iopub.execute_input":"2025-03-14T05:49:23.991697Z","iopub.status.idle":"2025-03-14T05:49:47.625553Z","shell.execute_reply.started":"2025-03-14T05:49:23.991667Z","shell.execute_reply":"2025-03-14T05:49:47.624762Z"}},"outputs":[{"name":"stdout","text":"Downloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolo11n-pose.pt to 'yolo11n-pose.pt'...\n","output_type":"stream"},{"name":"stderr","text":"100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5.97M/5.97M [00:00<00:00, 128MB/s]","output_type":"stream"},{"name":"stdout","text":"Ultralytics 8.3.89 ðŸš€ Python-3.10.12 torch-2.5.1+cu121 CUDA:0 (Tesla P100-PCIE-16GB, 16269MiB)\n\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=pose, mode=train, model=yolo11n-pose.pt, data=coco8-pose.yaml, epochs=3, time=None, patience=100, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=None, workers=8, project=None, name=train, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=True, opset=None, workspace=None, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, copy_paste_mode=flip, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=runs/pose/train\n\nDataset 'coco8-pose.yaml' images not found âš ï¸, missing path '/kaggle/working/datasets/coco8-pose/images/val'\nDownloading https://ultralytics.com/assets/coco8-pose.zip to '/kaggle/working/datasets/coco8-pose.zip'...\n","output_type":"stream"},{"name":"stderr","text":"\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 334k/334k [00:00<00:00, 17.4MB/s]\nUnzipping /kaggle/working/datasets/coco8-pose.zip to /kaggle/working/datasets/coco8-pose...: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 27/27 [00:00<00:00, 4739.92file/s]","output_type":"stream"},{"name":"stdout","text":"Dataset download success âœ… (0.6s), saved to \u001b[1m/kaggle/working/datasets\u001b[0m\n\nOverriding model.yaml nc=80 with nc=1\n\n                   from  n    params  module                                       arguments                     \n  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n  2                  -1  1      6640  ultralytics.nn.modules.block.C3k2            [32, 64, 1, False, 0.25]      \n  3                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n  4                  -1  1     26080  ultralytics.nn.modules.block.C3k2            [64, 128, 1, False, 0.25]     \n  5                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n  6                  -1  1     87040  ultralytics.nn.modules.block.C3k2            [128, 128, 1, True]           \n  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n  8                  -1  1    346112  ultralytics.nn.modules.block.C3k2            [256, 256, 1, True]           \n  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n 10                  -1  1    249728  ultralytics.nn.modules.block.C2PSA           [256, 256, 1]                 \n 11                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n 12             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n 13                  -1  1    111296  ultralytics.nn.modules.block.C3k2            [384, 128, 1, False]          \n 14                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n 15             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n 16                  -1  1     32096  ultralytics.nn.modules.block.C3k2            [256, 64, 1, False]           \n 17                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n 18            [-1, 13]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n 19                  -1  1     86720  ultralytics.nn.modules.block.C3k2            [192, 128, 1, False]          \n 20                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n 21            [-1, 10]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n 22                  -1  1    378880  ultralytics.nn.modules.block.C3k2            [384, 256, 1, True]           \n 23        [16, 19, 22]  1    715294  ultralytics.nn.modules.head.Pose             [1, [17, 3], [64, 128, 256]]  \n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"YOLO11n-pose summary: 196 layers, 2,874,462 parameters, 2,874,446 gradients, 7.5 GFLOPs\n\nTransferred 541/541 items from pretrained weights\n","output_type":"stream"},{"name":"stderr","text":"\u001b[1;38;5;214mCOMET WARNING:\u001b[0m To get all data logged automatically, import comet_ml before the following modules: torch.\n\u001b[1;38;5;214mCOMET WARNING:\u001b[0m As you are running in a Jupyter environment, you will need to call `experiment.end()` when finished to ensure all metrics and code are logged before exiting.\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m Experiment is live on comet.com https://www.comet.com/jamessuryaputra/general/96bdb91983b24753b8f5b6b560b48443\n\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m Couldn't find a Git repository in '/kaggle/working' nor in any parent directory. Set `COMET_GIT_DIRECTORY` if your Git Repository is elsewhere.\n","output_type":"stream"},{"name":"stdout","text":"\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/pose/train', view at http://localhost:6006/\nFreezing layer 'model.23.dfl.conv.weight'\n\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/datasets/coco8-pose/labels/train... 4 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 834.31it/s]","output_type":"stream"},{"name":"stdout","text":"\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/datasets/coco8-pose/labels/train.cache\n\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, num_output_channels=3, method='weighted_average'), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n","output_type":"stream"},{"name":"stderr","text":"\n\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/datasets/coco8-pose/labels/val... 4 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 256.94it/s]","output_type":"stream"},{"name":"stdout","text":"\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /kaggle/working/datasets/coco8-pose/labels/val.cache\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"Plotting labels to runs/pose/train/labels.jpg... \n\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.002, momentum=0.9) with parameter groups 87 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n\u001b[34m\u001b[1mTensorBoard: \u001b[0mmodel graph visualization added âœ…\nImage sizes 640 train, 640 val\nUsing 4 dataloader workers\nLogging results to \u001b[1mruns/pose/train\u001b[0m\nStarting training for 3 epochs...\n\n      Epoch    GPU_mem   box_loss  pose_loss  kobj_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"        1/3     0.879G      1.155      3.005     0.3014     0.7049       1.34          9        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.22it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Pose(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.19it/s]","output_type":"stream"},{"name":"stdout","text":"                   all          4         14      0.809      0.906      0.913      0.712          1      0.694      0.722      0.361\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss  pose_loss  kobj_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"        2/3     0.891G      1.309      4.784     0.2185      1.094      1.528         11        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  6.43it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Pose(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 13.13it/s]","output_type":"stream"},{"name":"stdout","text":"                   all          4         14       0.82      0.857      0.907       0.71      0.984      0.643      0.763      0.356\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss  pose_loss  kobj_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"        3/3     0.891G      1.414      4.013     0.4339      1.579      1.647         12        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  6.74it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Pose(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  9.39it/s]","output_type":"stream"},{"name":"stdout","text":"                   all          4         14        0.8      0.857      0.907      0.697      0.986      0.643      0.757      0.363\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n3 epochs completed in 0.002 hours.\nOptimizer stripped from runs/pose/train/weights/last.pt, 6.1MB\nOptimizer stripped from runs/pose/train/weights/best.pt, 6.1MB\n\nValidating runs/pose/train/weights/best.pt...\nUltralytics 8.3.89 ðŸš€ Python-3.10.12 torch-2.5.1+cu121 CUDA:0 (Tesla P100-PCIE-16GB, 16269MiB)\nYOLO11n-pose summary (fused): 109 layers, 2,866,468 parameters, 0 gradients, 7.4 GFLOPs\n","output_type":"stream"},{"name":"stderr","text":"                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Pose(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 21.23it/s]\n","output_type":"stream"},{"name":"stdout","text":"                   all          4         14      0.806      0.891      0.913      0.712          1      0.694      0.722       0.36\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n  xa[xa < 0] = -1\n/usr/local/lib/python3.10/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n  xa[xa < 0] = -1\n","output_type":"stream"},{"name":"stdout","text":"Speed: 0.2ms preprocess, 4.4ms inference, 0.0ms loss, 0.8ms postprocess per image\nResults saved to \u001b[1mruns/pose/train\u001b[0m\n","output_type":"stream"},{"name":"stderr","text":"\u001b[1;38;5;39mCOMET INFO:\u001b[0m ---------------------------------------------------------------------------------------\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m Comet.ml Experiment Summary\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m ---------------------------------------------------------------------------------------\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m   Data:\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     display_summary_level : 1\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     name                  : large_spoonbill_4169\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     url                   : https://www.comet.com/jamessuryaputra/general/96bdb91983b24753b8f5b6b560b48443\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m   Metrics [count] (min, max):\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     lr/pg0 [7]               : (0.0, 1.36e-05)\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     lr/pg1 [7]               : (0.0, 1.36e-05)\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     lr/pg2 [7]               : (0.0, 1.36e-05)\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     metrics/mAP50(B) [8]     : (0.90686, 0.9125011180679786)\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     metrics/mAP50(P) [8]     : (0.72218, 0.76275)\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     metrics/mAP50-95(B) [8]  : (0.69744, 0.7119635713178295)\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     metrics/mAP50-95(P) [8]  : (0.35574, 0.36294)\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     metrics/precision(B) [8] : (0.80003, 0.81973)\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     metrics/precision(P) [8] : (0.98432, 1.0)\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     metrics/recall(B) [8]    : (0.85714, 0.90585)\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     metrics/recall(P) [8]    : (0.64286, 0.6939559390217285)\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     model/GFLOPs             : 7.542\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     model/parameters         : 2874462\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     model/speed_PyTorch(ms)  : 13.05\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     train/box_loss [6]       : (1.15517, 1.41411)\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     train/cls_loss [6]       : (0.70491, 1.57934)\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     train/dfl_loss [6]       : (1.33994, 1.6467)\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     train/kobj_loss [6]      : (0.21851, 0.43386)\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     train/pose_loss [6]      : (3.00474, 4.78435)\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     val/box_loss [6]         : (0.88171, 0.89181)\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     val/cls_loss [6]         : (0.50139, 0.50812)\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     val/dfl_loss [6]         : (1.0893, 1.09521)\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     val/kobj_loss [6]        : (0.40126, 0.40546)\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     val/pose_loss [6]        : (3.72241, 3.79429)\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m   Others:\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     eval_batch_logging_interval  : 1\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     log_confusion_matrix_on_eval : False\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     log_image_predictions        : True\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     max_image_predictions        : 100\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m   Parameters:\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     agnostic_nms    : False\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     amp             : True\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     augment         : False\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     auto_augment    : randaugment\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     batch           : 16\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     bgr             : 0.0\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     box             : 7.5\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     cache           : False\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     cfg             : None\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     classes         : None\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     close_mosaic    : 10\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     cls             : 0.5\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     conf            : None\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     copy_paste      : 0.0\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     copy_paste_mode : flip\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     cos_lr          : False\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     crop_fraction   : 1.0\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     data            : /usr/local/lib/python3.10/dist-packages/ultralytics/cfg/datasets/coco8-pose.yaml\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     degrees         : 0.0\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     deterministic   : True\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     device          : None\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     dfl             : 1.5\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     dnn             : False\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     dropout         : 0.0\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     dynamic         : False\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     embed           : None\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     epochs          : 3\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     erasing         : 0.4\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     exist_ok        : False\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     fliplr          : 0.5\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     flipud          : 0.0\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     format          : torchscript\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     fraction        : 1.0\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     freeze          : None\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     half            : False\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     hsv_h           : 0.015\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     hsv_s           : 0.7\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     hsv_v           : 0.4\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     imgsz           : 640\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     int8            : False\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     iou             : 0.7\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     keras           : False\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     kobj            : 1.0\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     line_width      : None\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     lr0             : 0.01\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     lrf             : 0.01\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     mask_ratio      : 4\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     max_det         : 300\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     mixup           : 0.0\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     mode            : train\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     model           : yolo11n-pose.pt\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     momentum        : 0.937\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     mosaic          : 1.0\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     multi_scale     : False\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     name            : train\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     nbs             : 64\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     nms             : False\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     opset           : None\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     optimize        : False\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     optimizer       : auto\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     overlap_mask    : True\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     patience        : 100\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     perspective     : 0.0\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     plots           : True\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     pose            : 12.0\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     pretrained      : True\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     profile         : False\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     project         : None\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     rect            : False\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     resume          : False\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     retina_masks    : False\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     save            : True\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     save_conf       : False\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     save_crop       : False\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     save_dir        : runs/pose/train\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     save_frames     : False\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     save_hybrid     : False\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     save_json       : False\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     save_period     : -1\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     save_txt        : False\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     scale           : 0.5\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     seed            : 0\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     shear           : 0.0\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     show            : False\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     show_boxes      : True\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     show_conf       : True\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     show_labels     : True\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     simplify        : True\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     single_cls      : False\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     source          : None\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     split           : val\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     stream_buffer   : False\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     task            : pose\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     time            : None\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     tracker         : botsort.yaml\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     translate       : 0.1\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     val             : True\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     verbose         : True\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     vid_stride      : 1\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     visualize       : False\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     warmup_bias_lr  : 0.1\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     warmup_epochs   : 3.0\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     warmup_momentum : 0.8\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     weight_decay    : 0.0005\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     workers         : 8\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     workspace       : None\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m   Uploads:\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     confusion-matrix    : 1\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     environment details : 1\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     filename            : 1\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     images              : 17\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     installed packages  : 1\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     model-element       : 1 (5.77 MB)\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     notebook            : 1\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     os packages         : 1\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     source_code         : 1\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m \n\u001b[1;38;5;214mCOMET WARNING:\u001b[0m To get all data logged automatically, import comet_ml before the following modules: torch.\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m Please wait for assets to finish uploading (timeout is 10800 seconds)\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m All assets have been sent, waiting for delivery confirmation\n","output_type":"stream"},{"name":"stdout","text":"\nFound https://ultralytics.com/images/bus.jpg locally at bus.jpg\nimage 1/1 /kaggle/working/bus.jpg: 640x480 4 persons, 21.1ms\nSpeed: 3.3ms preprocess, 21.1ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 480)\n","output_type":"stream"},{"execution_count":12,"output_type":"execute_result","data":{"text/plain":"[ultralytics.engine.results.Results object with attributes:\n \n boxes: ultralytics.engine.results.Boxes object\n keypoints: ultralytics.engine.results.Keypoints object\n masks: None\n names: {0: 'person'}\n obb: None\n orig_img: array([[[119, 146, 172],\n         [121, 148, 174],\n         [122, 152, 177],\n         ...,\n         [161, 171, 188],\n         [160, 170, 187],\n         [160, 170, 187]],\n \n        [[120, 147, 173],\n         [122, 149, 175],\n         [123, 153, 178],\n         ...,\n         [161, 171, 188],\n         [160, 170, 187],\n         [160, 170, 187]],\n \n        [[123, 150, 176],\n         [124, 151, 177],\n         [125, 155, 180],\n         ...,\n         [161, 171, 188],\n         [160, 170, 187],\n         [160, 170, 187]],\n \n        ...,\n \n        [[183, 182, 186],\n         [179, 178, 182],\n         [180, 179, 183],\n         ...,\n         [121, 111, 117],\n         [113, 103, 109],\n         [115, 105, 111]],\n \n        [[165, 164, 168],\n         [173, 172, 176],\n         [187, 186, 190],\n         ...,\n         [102,  92,  98],\n         [101,  91,  97],\n         [103,  93,  99]],\n \n        [[123, 122, 126],\n         [145, 144, 148],\n         [176, 175, 179],\n         ...,\n         [ 95,  85,  91],\n         [ 96,  86,  92],\n         [ 98,  88,  94]]], dtype=uint8)\n orig_shape: (1080, 810)\n path: '/kaggle/working/bus.jpg'\n probs: None\n save_dir: 'runs/pose/train2'\n speed: {'preprocess': 3.3010649999596353, 'inference': 21.05001700010689, 'postprocess': 1.9717410000339441}]"},"metadata":{}}],"execution_count":12},{"cell_type":"markdown","source":"## 5th task: Oriented Bounding Boxes (OBB)","metadata":{}},{"cell_type":"code","source":"# Load the model (yolo11n-obb) and train on COCO128 (for 3 epochs), then predict the image\nfrom ultralytics import YOLO\n\nmodel = YOLO('yolo11n-obb.pt')\nmodel.train(data='dota8.yaml', epochs=3)\nmodel('https://ultralytics.com/images/boats.jpg')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-14T05:49:47.626688Z","iopub.execute_input":"2025-03-14T05:49:47.627083Z","iopub.status.idle":"2025-03-14T05:50:13.807410Z","shell.execute_reply.started":"2025-03-14T05:49:47.627023Z","shell.execute_reply":"2025-03-14T05:50:13.806634Z"}},"outputs":[{"name":"stdout","text":"Downloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolo11n-obb.pt to 'yolo11n-obb.pt'...\n","output_type":"stream"},{"name":"stderr","text":"100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5.53M/5.53M [00:00<00:00, 112MB/s]","output_type":"stream"},{"name":"stdout","text":"Ultralytics 8.3.89 ðŸš€ Python-3.10.12 torch-2.5.1+cu121 CUDA:0 (Tesla P100-PCIE-16GB, 16269MiB)\n\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=obb, mode=train, model=yolo11n-obb.pt, data=dota8.yaml, epochs=3, time=None, patience=100, batch=16, imgsz=1024, save=True, save_period=-1, cache=False, device=None, workers=8, project=None, name=train, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=True, opset=None, workspace=None, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, copy_paste_mode=flip, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=runs/obb/train\n\nDataset 'dota8.yaml' images not found âš ï¸, missing path '/kaggle/working/datasets/dota8/images/val'\nDownloading https://ultralytics.com/assets/dota8.zip to '/kaggle/working/datasets/dota8.zip'...\n","output_type":"stream"},{"name":"stderr","text":"\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1.24M/1.24M [00:00<00:00, 36.4MB/s]\nUnzipping /kaggle/working/datasets/dota8.zip to /kaggle/working/datasets/dota8...: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 27/27 [00:00<00:00, 1979.93file/s]","output_type":"stream"},{"name":"stdout","text":"Dataset download success âœ… (0.7s), saved to \u001b[1m/kaggle/working/datasets\u001b[0m\n\nOverriding model.yaml nc=80 with nc=15\n\n                   from  n    params  module                                       arguments                     \n  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n  2                  -1  1      6640  ultralytics.nn.modules.block.C3k2            [32, 64, 1, False, 0.25]      \n  3                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n  4                  -1  1     26080  ultralytics.nn.modules.block.C3k2            [64, 128, 1, False, 0.25]     \n  5                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n  6                  -1  1     87040  ultralytics.nn.modules.block.C3k2            [128, 128, 1, True]           \n  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n  8                  -1  1    346112  ultralytics.nn.modules.block.C3k2            [256, 256, 1, True]           \n  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n 10                  -1  1    249728  ultralytics.nn.modules.block.C2PSA           [256, 256, 1]                 \n 11                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n 12             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n 13                  -1  1    111296  ultralytics.nn.modules.block.C3k2            [384, 128, 1, False]          \n 14                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n 15             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n 16                  -1  1     32096  ultralytics.nn.modules.block.C3k2            [256, 64, 1, False]           \n 17                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n 18            [-1, 13]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n 19                  -1  1     86720  ultralytics.nn.modules.block.C3k2            [192, 128, 1, False]          \n 20                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n 21            [-1, 10]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n 22                  -1  1    378880  ultralytics.nn.modules.block.C3k2            [384, 256, 1, True]           \n 23        [16, 19, 22]  1    505264  ultralytics.nn.modules.head.OBB              [15, 1, [64, 128, 256]]       \n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"YOLO11n-obb summary: 196 layers, 2,664,432 parameters, 2,664,416 gradients, 6.7 GFLOPs\n\nTransferred 541/541 items from pretrained weights\n","output_type":"stream"},{"name":"stderr","text":"\u001b[1;38;5;214mCOMET WARNING:\u001b[0m To get all data logged automatically, import comet_ml before the following modules: torch.\n\u001b[1;38;5;214mCOMET WARNING:\u001b[0m As you are running in a Jupyter environment, you will need to call `experiment.end()` when finished to ensure all metrics and code are logged before exiting.\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m Experiment is live on comet.com https://www.comet.com/jamessuryaputra/general/708ddc990a6c44e6879e86af4693739e\n\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m Couldn't find a Git repository in '/kaggle/working' nor in any parent directory. Set `COMET_GIT_DIRECTORY` if your Git Repository is elsewhere.\n","output_type":"stream"},{"name":"stdout","text":"\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/obb/train', view at http://localhost:6006/\nFreezing layer 'model.23.dfl.conv.weight'\n\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/datasets/dota8/labels/train... 4 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 655.08it/s]","output_type":"stream"},{"name":"stdout","text":"\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/datasets/dota8/labels/train.cache\n\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, num_output_channels=3, method='weighted_average'), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n","output_type":"stream"},{"name":"stderr","text":"\n\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/datasets/dota8/labels/val... 4 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 1853.84it/s]","output_type":"stream"},{"name":"stdout","text":"\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /kaggle/working/datasets/dota8/labels/val.cache\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"Plotting labels to runs/obb/train/labels.jpg... \n\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.000526, momentum=0.9) with parameter groups 87 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n\u001b[34m\u001b[1mTensorBoard: \u001b[0mmodel graph visualization added âœ…\nImage sizes 1024 train, 1024 val\nUsing 4 dataloader workers\nLogging results to \u001b[1mruns/obb/train\u001b[0m\nStarting training for 3 epochs...\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"        1/3      1.85G     0.8831      0.558       1.76        156       1024: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  2.73it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  5.33it/s]","output_type":"stream"},{"name":"stdout","text":"                   all          4          8      0.944          1      0.995      0.804\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"        2/3      1.85G     0.9367     0.5685      1.796        232       1024: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  3.91it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  5.48it/s]","output_type":"stream"},{"name":"stdout","text":"                   all          4          8      0.945          1      0.995      0.804\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"        3/3      1.85G     0.5905     0.6189      1.247         38       1024: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  2.57it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.87it/s]","output_type":"stream"},{"name":"stdout","text":"                   all          4          8      0.946          1      0.995      0.804\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n3 epochs completed in 0.002 hours.\nOptimizer stripped from runs/obb/train/weights/last.pt, 5.9MB\nOptimizer stripped from runs/obb/train/weights/best.pt, 5.9MB\n\nValidating runs/obb/train/weights/best.pt...\nUltralytics 8.3.89 ðŸš€ Python-3.10.12 torch-2.5.1+cu121 CUDA:0 (Tesla P100-PCIE-16GB, 16269MiB)\nYOLO11n-obb summary (fused): 109 layers, 2,656,648 parameters, 0 gradients, 6.6 GFLOPs\n","output_type":"stream"},{"name":"stderr","text":"                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 14.87it/s]\n","output_type":"stream"},{"name":"stdout","text":"                   all          4          8      0.945          1      0.995      0.804\n      baseball diamond          3          4      0.896          1      0.995       0.85\n      basketball court          1          3      0.976          1      0.995      0.866\n     soccer ball field          1          1      0.964          1      0.995      0.697\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n  xa[xa < 0] = -1\n/usr/local/lib/python3.10/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n  xa[xa < 0] = -1\n","output_type":"stream"},{"name":"stdout","text":"Speed: 0.4ms preprocess, 6.8ms inference, 0.0ms loss, 3.6ms postprocess per image\nResults saved to \u001b[1mruns/obb/train\u001b[0m\n","output_type":"stream"},{"name":"stderr","text":"\u001b[1;38;5;39mCOMET INFO:\u001b[0m ---------------------------------------------------------------------------------------\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m Comet.ml Experiment Summary\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m ---------------------------------------------------------------------------------------\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m   Data:\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     display_summary_level : 1\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     name                  : productive_damper_8035\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     url                   : https://www.comet.com/jamessuryaputra/general/708ddc990a6c44e6879e86af4693739e\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m   Metrics [count] (min, max):\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     lr/pg0 [7]               : (0.0, 3.5768e-06)\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     lr/pg1 [7]               : (0.0, 3.5768e-06)\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     lr/pg2 [7]               : (0.0, 3.5768e-06)\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     metrics/mAP50(B)         : 0.995\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     metrics/mAP50-95(B) [8]  : (0.80425, 0.8043716666666667)\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     metrics/precision(B) [8] : (0.94439, 0.9459)\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     metrics/recall(B)        : 1.0\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     model/GFLOPs             : 6.703\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     model/parameters         : 2664432\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     model/speed_PyTorch(ms)  : 26.801\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     train/box_loss [6]       : (0.59054, 0.93673)\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     train/cls_loss [6]       : (0.558, 0.61889)\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     train/dfl_loss [6]       : (1.24677, 1.79556)\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     val/box_loss [6]         : (0.78706, 0.7938)\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     val/cls_loss [6]         : (0.39647, 0.40362)\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     val/dfl_loss [6]         : (2.12323, 2.13781)\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m   Others:\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     eval_batch_logging_interval  : 1\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     log_confusion_matrix_on_eval : False\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     log_image_predictions        : True\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     max_image_predictions        : 100\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m   Parameters:\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     agnostic_nms    : False\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     amp             : True\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     augment         : False\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     auto_augment    : randaugment\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     batch           : 16\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     bgr             : 0.0\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     box             : 7.5\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     cache           : False\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     cfg             : None\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     classes         : None\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     close_mosaic    : 10\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     cls             : 0.5\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     conf            : None\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     copy_paste      : 0.0\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     copy_paste_mode : flip\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     cos_lr          : False\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     crop_fraction   : 1.0\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     data            : /usr/local/lib/python3.10/dist-packages/ultralytics/cfg/datasets/dota8.yaml\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     degrees         : 0.0\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     deterministic   : True\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     device          : None\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     dfl             : 1.5\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     dnn             : False\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     dropout         : 0.0\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     dynamic         : False\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     embed           : None\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     epochs          : 3\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     erasing         : 0.4\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     exist_ok        : False\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     fliplr          : 0.5\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     flipud          : 0.0\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     format          : torchscript\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     fraction        : 1.0\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     freeze          : None\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     half            : False\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     hsv_h           : 0.015\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     hsv_s           : 0.7\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     hsv_v           : 0.4\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     imgsz           : 1024\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     int8            : False\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     iou             : 0.7\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     keras           : False\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     kobj            : 1.0\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     line_width      : None\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     lr0             : 0.01\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     lrf             : 0.01\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     mask_ratio      : 4\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     max_det         : 300\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     mixup           : 0.0\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     mode            : train\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     model           : yolo11n-obb.pt\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     momentum        : 0.937\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     mosaic          : 1.0\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     multi_scale     : False\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     name            : train\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     nbs             : 64\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     nms             : False\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     opset           : None\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     optimize        : False\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     optimizer       : auto\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     overlap_mask    : True\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     patience        : 100\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     perspective     : 0.0\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     plots           : True\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     pose            : 12.0\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     pretrained      : True\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     profile         : False\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     project         : None\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     rect            : False\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     resume          : False\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     retina_masks    : False\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     save            : True\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     save_conf       : False\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     save_crop       : False\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     save_dir        : runs/obb/train\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     save_frames     : False\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     save_hybrid     : False\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     save_json       : False\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     save_period     : -1\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     save_txt        : False\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     scale           : 0.5\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     seed            : 0\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     shear           : 0.0\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     show            : False\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     show_boxes      : True\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     show_conf       : True\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     show_labels     : True\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     simplify        : True\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     single_cls      : False\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     source          : None\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     split           : val\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     stream_buffer   : False\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     task            : obb\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     time            : None\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     tracker         : botsort.yaml\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     translate       : 0.1\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     val             : True\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     verbose         : True\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     vid_stride      : 1\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     visualize       : False\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     warmup_bias_lr  : 0.1\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     warmup_epochs   : 3.0\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     warmup_momentum : 0.8\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     weight_decay    : 0.0005\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     workers         : 8\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     workspace       : None\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m   Uploads:\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     confusion-matrix    : 1\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     environment details : 1\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     filename            : 1\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     images              : 13\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     installed packages  : 1\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     model-element       : 1 (5.62 MB)\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     notebook            : 1\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     os packages         : 1\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     source_code         : 1\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m \n\u001b[1;38;5;214mCOMET WARNING:\u001b[0m To get all data logged automatically, import comet_ml before the following modules: torch.\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m Please wait for assets to finish uploading (timeout is 10800 seconds)\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m All assets have been sent, waiting for delivery confirmation\n","output_type":"stream"},{"name":"stdout","text":"\nDownloading https://ultralytics.com/images/boats.jpg to 'boats.jpg'...\n","output_type":"stream"},{"name":"stderr","text":"100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 190k/190k [00:00<00:00, 11.8MB/s]","output_type":"stream"},{"name":"stdout","text":"image 1/1 /kaggle/working/boats.jpg: 576x1024 51.2ms\nSpeed: 4.1ms preprocess, 51.2ms inference, 5.2ms postprocess per image at shape (1, 3, 576, 1024)\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"execution_count":13,"output_type":"execute_result","data":{"text/plain":"[ultralytics.engine.results.Results object with attributes:\n \n boxes: None\n keypoints: None\n masks: None\n names: {0: 'plane', 1: 'ship', 2: 'storage tank', 3: 'baseball diamond', 4: 'tennis court', 5: 'basketball court', 6: 'ground track field', 7: 'harbor', 8: 'bridge', 9: 'large vehicle', 10: 'small vehicle', 11: 'helicopter', 12: 'roundabout', 13: 'soccer ball field', 14: 'swimming pool'}\n obb: ultralytics.engine.results.OBB object\n orig_img: array([[[ 40,  68, 103],\n         [ 29,  56,  90],\n         [ 14,  36,  64],\n         ...,\n         [ 86, 100,  94],\n         [ 88, 102,  96],\n         [ 92, 106, 100]],\n \n        [[ 64,  95, 128],\n         [ 54,  83, 114],\n         [ 39,  66,  92],\n         ...,\n         [ 83,  97,  91],\n         [ 82,  96,  90],\n         [ 82,  96,  90]],\n \n        [[ 77, 117, 142],\n         [ 73, 111, 135],\n         [ 69, 103, 126],\n         ...,\n         [ 62,  74,  68],\n         [ 64,  78,  72],\n         [ 65,  79,  73]],\n \n        ...,\n \n        [[ 62,  60,  52],\n         [ 63,  61,  53],\n         [ 58,  56,  48],\n         ...,\n         [ 24,  32,   9],\n         [ 24,  32,   9],\n         [ 24,  32,   9]],\n \n        [[ 62,  60,  52],\n         [ 63,  61,  53],\n         [ 60,  58,  50],\n         ...,\n         [ 24,  32,   9],\n         [ 24,  32,   9],\n         [ 24,  32,   9]],\n \n        [[ 61,  59,  51],\n         [ 64,  62,  54],\n         [ 63,  61,  53],\n         ...,\n         [ 24,  32,   9],\n         [ 24,  32,   9],\n         [ 24,  32,   9]]], dtype=uint8)\n orig_shape: (1080, 1920)\n path: '/kaggle/working/boats.jpg'\n probs: None\n save_dir: 'runs/obb/train2'\n speed: {'preprocess': 4.083759999957692, 'inference': 51.18654800003242, 'postprocess': 5.16284800005451}]"},"metadata":{}}],"execution_count":13}]}