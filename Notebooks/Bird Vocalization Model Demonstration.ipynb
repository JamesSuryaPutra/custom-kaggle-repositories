{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":3836,"sourceType":"modelInstanceVersion","isSourceIdPinned":true,"modelInstanceId":2739,"modelId":319}],"dockerImageVersionId":30919,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Preparation","metadata":{}},{"cell_type":"code","source":"# Import audio function modules\nimport tensorflow as tf\nimport tensorflow_hub as hub\nimport tensorflow_io as tfio\n\n# Import main modules\nimport numpy as np\nimport librosa\nimport csv\nimport io","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-28T07:55:40.075249Z","iopub.execute_input":"2025-03-28T07:55:40.075716Z","iopub.status.idle":"2025-03-28T07:55:40.080576Z","shell.execute_reply.started":"2025-03-28T07:55:40.075676Z","shell.execute_reply":"2025-03-28T07:55:40.079562Z"}},"outputs":[],"execution_count":35},{"cell_type":"code","source":"# Load the model from TFHub\nmodel_handle = \"https://tfhub.dev/google/bird-vocalization-classifier/1\"\nmodel = hub.load(model_handle)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-28T07:55:40.081609Z","iopub.execute_input":"2025-03-28T07:55:40.081919Z","iopub.status.idle":"2025-03-28T07:55:45.301793Z","shell.execute_reply.started":"2025-03-28T07:55:40.081891Z","shell.execute_reply":"2025-03-28T07:55:45.300900Z"}},"outputs":[],"execution_count":36},{"cell_type":"markdown","source":"# Loading labels","metadata":{}},{"cell_type":"code","source":"# Find the trained labels\ndef class_names_from_csv(class_map_csv_text):\n    with open(labels_path) as csv_file:\n        csv_reader = csv.reader(csv_file, delimiter=',')\n        class_names = [mid for mid, desc in csv_reader]\n        return class_names[:1]\n\nlabels_path = hub.resolve(model_handle) + \"/assets/label.csv\"\nclasses = class_names_from_csv(labels_path)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-28T07:55:45.304520Z","iopub.execute_input":"2025-03-28T07:55:45.304786Z","iopub.status.idle":"2025-03-28T07:55:45.314123Z","shell.execute_reply.started":"2025-03-28T07:55:45.304765Z","shell.execute_reply":"2025-03-28T07:55:45.313222Z"}},"outputs":[],"execution_count":37},{"cell_type":"markdown","source":"# Resampling","metadata":{}},{"cell_type":"code","source":"# Define sampling rate function parameters\ndef frame_audio(\n    audio_array: np.ndarray,\n    window_size_s: float=5.0,\n    hop_size_s: float=5.0,\n    sample_rate=32000\n) -> np.ndarray:\n    if window_size_s is None or window_size_s < 0:\n        return audio_array[np.newaxis, :]\n    frame_length = int(window_size_s * sample_rate)\n    hop_length = int(hop_size_s * sample_rate)\n    framed_audio = tf.signal.frame(audio_array, frame_length, hop_length, pad_end=True)\n    return framed_audio\n\ndef ensure_sample_rate(\n    waveform,\n    original_sample_rate,\n    desired_sample_rate=32000\n):\n    if original_sample_rate != desired_sample_rate:\n        waveform = tfio.audio.resample(waveform, original_sample_rate, desired_sample_rate)\n    return desired_sample_rate, waveform","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-28T07:55:45.315461Z","iopub.execute_input":"2025-03-28T07:55:45.315791Z","iopub.status.idle":"2025-03-28T07:55:45.331060Z","shell.execute_reply.started":"2025-03-28T07:55:45.315760Z","shell.execute_reply":"2025-03-28T07:55:45.330150Z"}},"outputs":[],"execution_count":38},{"cell_type":"markdown","source":"# Load the audio file","metadata":{}},{"cell_type":"code","source":"# Load the audio file from any websites (e.g., Wikipedia)\n!curl -O \"https://upload.wikimedia.org/wikipedia/commons/7/7c/Turdus_merula_2.ogg\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-28T07:55:45.331978Z","iopub.execute_input":"2025-03-28T07:55:45.332341Z","iopub.status.idle":"2025-03-28T07:55:45.776208Z","shell.execute_reply.started":"2025-03-28T07:55:45.332312Z","shell.execute_reply":"2025-03-28T07:55:45.774997Z"}},"outputs":[{"name":"stdout","text":"  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n                                 Dload  Upload   Total   Spent    Left  Speed\n100  306k  100  306k    0     0  1171k      0 --:--:-- --:--:-- --:--:-- 1175k\n","output_type":"stream"}],"execution_count":39},{"cell_type":"code","source":"# Identify the audio sample\nturdus_merula = \"Turdus_merula_2.ogg\"\n\naudio, sample_rate = librosa.load(turdus_merula)\n\nsample_rate, wav_data_turdus = ensure_sample_rate(audio, sample_rate)\naudio","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-28T07:55:45.777342Z","iopub.execute_input":"2025-03-28T07:55:45.777726Z","iopub.status.idle":"2025-03-28T07:55:46.232898Z","shell.execute_reply.started":"2025-03-28T07:55:45.777691Z","shell.execute_reply":"2025-03-28T07:55:46.231890Z"}},"outputs":[{"execution_count":40,"output_type":"execute_result","data":{"text/plain":"array([-1.1987052e-05,  3.2027947e-06,  1.1725351e-06, ...,\n        2.0122516e-05, -1.0682907e-05,  2.0385552e-05], dtype=float32)"},"metadata":{}}],"execution_count":40},{"cell_type":"markdown","source":"# Split the audio","metadata":{}},{"cell_type":"code","source":"# Convert the audio sample\nfixed_tm = frame_audio(wav_data_turdus)\nfixed_tm.shape","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-28T07:55:46.233944Z","iopub.execute_input":"2025-03-28T07:55:46.234297Z","iopub.status.idle":"2025-03-28T07:55:46.251000Z","shell.execute_reply.started":"2025-03-28T07:55:46.234267Z","shell.execute_reply":"2025-03-28T07:55:46.250159Z"}},"outputs":[{"execution_count":41,"output_type":"execute_result","data":{"text/plain":"TensorShape([5, 160000])"},"metadata":{}}],"execution_count":41},{"cell_type":"markdown","source":"# Model application","metadata":{}},{"cell_type":"code","source":"# Apply the model on a single frame\nlogits, embeddings = model.infer_tf(fixed_tm[:1])\n\nprobabilities = tf.nn.softmax(logits)\nargmax = np.argmax(probabilities)\n\nlogits.shape","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-28T07:55:46.253345Z","iopub.execute_input":"2025-03-28T07:55:46.253599Z","iopub.status.idle":"2025-03-28T07:55:50.745616Z","shell.execute_reply.started":"2025-03-28T07:55:46.253573Z","shell.execute_reply":"2025-03-28T07:55:50.744830Z"}},"outputs":[{"execution_count":42,"output_type":"execute_result","data":{"text/plain":"TensorShape([1, 10932])"},"metadata":{}}],"execution_count":42},{"cell_type":"code","source":"# Apply the model on all frames (Step 1)\nall_logits, all_embeddings = model.infer_tf(fixed_tm[:1])\nfor window in fixed_tm[:1]:\n    logits, embeddings = model.infer_tf(window[np.newaxis, :])\n    all_logits = np.concatenate([all_logits, logits], axis=0)\n\nall_logits.shape","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-28T07:55:50.746528Z","iopub.execute_input":"2025-03-28T07:55:50.746819Z","iopub.status.idle":"2025-03-28T07:55:50.770362Z","shell.execute_reply.started":"2025-03-28T07:55:50.746778Z","shell.execute_reply":"2025-03-28T07:55:50.769522Z"}},"outputs":[{"execution_count":43,"output_type":"execute_result","data":{"text/plain":"(2, 10932)"},"metadata":{}}],"execution_count":43},{"cell_type":"code","source":"# Apply the model on all frames (Step 2)\nframe = 0\n\nfor frame_logits in all_logits:\n    probabilities = tf.nn.softmax(frame_logits)\n    argmax = np.argmax(probabilities)\n\n    frame += 1","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-28T07:55:50.771118Z","iopub.execute_input":"2025-03-28T07:55:50.771326Z","iopub.status.idle":"2025-03-28T07:55:50.776374Z","shell.execute_reply.started":"2025-03-28T07:55:50.771309Z","shell.execute_reply":"2025-03-28T07:55:50.775655Z"}},"outputs":[],"execution_count":44}]}